2020-11-27T20:01:49 (asr.sh:214:main) ./asr.sh --lang en --use_lm false --token_type char --nbpe 80 --nlsyms_txt data/nlsyms.txt --lm_config conf/train_lm_transformer.yaml --asr_config conf/train_asr_transformer.yaml --inference_config conf/decode.yaml --train_set train_si84 --valid_set test_dev93 --test_sets test_dev93 test_eval92 --bpe_train_text data/train_si284/text --lm_train_text data/train_si284/text data/local/other_text/text --ngpu 1 --feats_type fbank_pitch
2020-11-27T20:01:49 (asr.sh:214:main) ./asr.sh --lang en --use_lm false --token_type char --nbpe 80 --nlsyms_txt data/nlsyms.txt --lm_config conf/train_lm_transformer.yaml --asr_config conf/train_asr_transformer.yaml --inference_config conf/decode.yaml --train_set train_si84 --valid_set test_dev93 --test_sets test_dev93 test_eval92 --bpe_train_text data/train_si284/text --lm_train_text data/train_si284/text data/local/other_text/text --ngpu 1 --feats_type fbank_pitch
2020-11-27T20:01:52 (asr.sh:364:main) Stage 1: Data preparation for data/train_si84, data/test_dev93, etc.
2020-11-27T20:01:52 (asr.sh:364:main) Stage 1: Data preparation for data/train_si84, data/test_dev93, etc.
2020-11-27T20:01:52 (data.sh:37:main) local/wsj_data_prep.sh /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_1/??-{?,??}.? /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/??-{?,??}.?
2020-11-27T20:01:52 (data.sh:37:main) local/wsj_data_prep.sh /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_1/??-{?,??}.? /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/??-{?,??}.?
Data preparation succeeded
2020-11-27T20:03:56 (data.sh:39:main) local/wsj_format_data.sh
local/wsj_format_data.sh 
Data preparation succeeded
2020-11-27T20:03:56 (data.sh:39:main) local/wsj_format_data.sh
local/wsj_format_data.sh 
Preparing train and test data
Preparing train and test data
Succeeded in formatting data.
2020-11-27T20:03:59 (data.sh:43:main) Prepare text from lng_modl dir: /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/13-32.1/wsj1/doc/lng_modl/lm_train/np_data/{87,88,89}/*.z -> data/local/other_text/text
Succeeded in formatting data.
2020-11-27T20:03:59 (data.sh:43:main) Prepare text from lng_modl dir: /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/13-32.1/wsj1/doc/lng_modl/lm_train/np_data/{87,88,89}/*.z -> data/local/other_text/text
2020-11-27T20:04:55 (data.sh:53:main) Create non linguistic symbols: data/nlsyms.txt
2020-11-27T20:04:55 (data.sh:53:main) Create non linguistic symbols: data/nlsyms.txt
<*IN*>
<*MR.*>
<NOISE>
2020-11-27T20:04:55 (asr.sh:383:main) Skip stage 2: Speed perturbation
2020-11-27T20:04:55 (asr.sh:429:main) [Require Kaldi] Stage 3: fbank_pitch extract: data/ -> dump/fbank_pitch
<*IN*>
<*MR.*>
<NOISE>
2020-11-27T20:04:55 (asr.sh:383:main) Skip stage 2: Speed perturbation
2020-11-27T20:04:55 (asr.sh:429:main) [Require Kaldi] Stage 3: fbank_pitch extract: data/ -> dump/fbank_pitch
utils/copy_data_dir.sh: copied data from data/train_si84 to dump/fbank_pitch/org/train_si84
utils/copy_data_dir.sh: copied data from data/train_si84 to dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
2020-11-27T20:05:04 (asr.sh:214:main) ./asr.sh --lang en --use_lm false --token_type char --nbpe 80 --nlsyms_txt data/nlsyms.txt --lm_config conf/train_lm_transformer.yaml --asr_config conf/train_asr_transformer.yaml --inference_config conf/decode.yaml --train_set train_si84 --valid_set test_dev93 --test_sets test_dev93 test_eval92 --bpe_train_text data/train_si284/text --lm_train_text data/train_si284/text data/local/other_text/text --ngpu 1 --feats_type fbank_pitch
2020-11-27T20:05:04 (asr.sh:214:main) ./asr.sh --lang en --use_lm false --token_type char --nbpe 80 --nlsyms_txt data/nlsyms.txt --lm_config conf/train_lm_transformer.yaml --asr_config conf/train_asr_transformer.yaml --inference_config conf/decode.yaml --train_set train_si84 --valid_set test_dev93 --test_sets test_dev93 test_eval92 --bpe_train_text data/train_si284/text --lm_train_text data/train_si284/text data/local/other_text/text --ngpu 1 --feats_type fbank_pitch
2020-11-27T20:05:05 (asr.sh:364:main) Stage 1: Data preparation for data/train_si84, data/test_dev93, etc.
2020-11-27T20:05:05 (asr.sh:364:main) Stage 1: Data preparation for data/train_si84, data/test_dev93, etc.
2020-11-27T20:05:05 (data.sh:37:main) local/wsj_data_prep.sh /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_1/??-{?,??}.? /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/??-{?,??}.?
2020-11-27T20:05:05 (data.sh:37:main) local/wsj_data_prep.sh /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_1/??-{?,??}.? /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/??-{?,??}.?
Data preparation succeeded
2020-11-27T20:05:31 (data.sh:39:main) local/wsj_format_data.sh
local/wsj_format_data.sh 
Data preparation succeeded
2020-11-27T20:05:31 (data.sh:39:main) local/wsj_format_data.sh
local/wsj_format_data.sh 
Preparing train and test data
Preparing train and test data
Succeeded in formatting data.
Succeeded in formatting data.
2020-11-27T20:05:34 (data.sh:43:main) Prepare text from lng_modl dir: /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/13-32.1/wsj1/doc/lng_modl/lm_train/np_data/{87,88,89}/*.z -> data/local/other_text/text
2020-11-27T20:05:34 (data.sh:43:main) Prepare text from lng_modl dir: /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/13-32.1/wsj1/doc/lng_modl/lm_train/np_data/{87,88,89}/*.z -> data/local/other_text/text
2020-11-27T20:06:17 (data.sh:53:main) Create non linguistic symbols: data/nlsyms.txt
2020-11-27T20:06:17 (data.sh:53:main) Create non linguistic symbols: data/nlsyms.txt
<*IN*>
<*MR.*>
<NOISE>
2020-11-27T20:06:17 (asr.sh:383:main) Skip stage 2: Speed perturbation
2020-11-27T20:06:17 (asr.sh:429:main) [Require Kaldi] Stage 3: fbank_pitch extract: data/ -> dump/fbank_pitch
<*IN*>
<*MR.*>
<NOISE>
2020-11-27T20:06:17 (asr.sh:383:main) Skip stage 2: Speed perturbation
2020-11-27T20:06:17 (asr.sh:429:main) [Require Kaldi] Stage 3: fbank_pitch extract: data/ -> dump/fbank_pitch
utils/copy_data_dir.sh: copied data from data/train_si84 to dump/fbank_pitch/org/train_si84
utils/copy_data_dir.sh: copied data from data/train_si84 to dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
2020-11-27T20:08:16 (asr.sh:214:main) ./asr.sh --lang en --use_lm false --token_type char --nbpe 80 --nlsyms_txt data/nlsyms.txt --lm_config conf/train_lm_transformer.yaml --asr_config conf/train_asr_transformer.yaml --inference_config conf/decode.yaml --train_set train_si84 --valid_set test_dev93 --test_sets test_dev93 test_eval92 --bpe_train_text data/train_si284/text --lm_train_text data/train_si284/text data/local/other_text/text --ngpu 1 --feats_type fbank_pitch
2020-11-27T20:08:16 (asr.sh:214:main) ./asr.sh --lang en --use_lm false --token_type char --nbpe 80 --nlsyms_txt data/nlsyms.txt --lm_config conf/train_lm_transformer.yaml --asr_config conf/train_asr_transformer.yaml --inference_config conf/decode.yaml --train_set train_si84 --valid_set test_dev93 --test_sets test_dev93 test_eval92 --bpe_train_text data/train_si284/text --lm_train_text data/train_si284/text data/local/other_text/text --ngpu 1 --feats_type fbank_pitch
2020-11-27T20:08:16 (asr.sh:364:main) Stage 1: Data preparation for data/train_si84, data/test_dev93, etc.
2020-11-27T20:08:16 (data.sh:37:main) local/wsj_data_prep.sh /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_1/??-{?,??}.? /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/??-{?,??}.?
2020-11-27T20:08:16 (asr.sh:364:main) Stage 1: Data preparation for data/train_si84, data/test_dev93, etc.
2020-11-27T20:08:16 (data.sh:37:main) local/wsj_data_prep.sh /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_1/??-{?,??}.? /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/??-{?,??}.?
Data preparation succeeded
2020-11-27T20:08:42 (data.sh:39:main) local/wsj_format_data.sh
local/wsj_format_data.sh 
Data preparation succeeded
2020-11-27T20:08:42 (data.sh:39:main) local/wsj_format_data.sh
local/wsj_format_data.sh 
Preparing train and test data
Preparing train and test data
Succeeded in formatting data.
2020-11-27T20:08:45 (data.sh:43:main) Prepare text from lng_modl dir: /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/13-32.1/wsj1/doc/lng_modl/lm_train/np_data/{87,88,89}/*.z -> data/local/other_text/text
Succeeded in formatting data.
2020-11-27T20:08:45 (data.sh:43:main) Prepare text from lng_modl dir: /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/13-32.1/wsj1/doc/lng_modl/lm_train/np_data/{87,88,89}/*.z -> data/local/other_text/text
2020-11-27T20:09:28 (data.sh:53:main) Create non linguistic symbols: data/nlsyms.txt
2020-11-27T20:09:28 (data.sh:53:main) Create non linguistic symbols: data/nlsyms.txt
<*IN*>
<*MR.*>
<NOISE>
2020-11-27T20:09:28 (asr.sh:383:main) Skip stage 2: Speed perturbation
2020-11-27T20:09:28 (asr.sh:429:main) [Require Kaldi] Stage 3: fbank_pitch extract: data/ -> dump/fbank_pitch
<*IN*>
<*MR.*>
<NOISE>
2020-11-27T20:09:28 (asr.sh:383:main) Skip stage 2: Speed perturbation
2020-11-27T20:09:28 (asr.sh:429:main) [Require Kaldi] Stage 3: fbank_pitch extract: data/ -> dump/fbank_pitch
utils/copy_data_dir.sh: copied data from data/train_si84 to dump/fbank_pitch/org/train_si84
utils/copy_data_dir.sh: copied data from data/train_si84 to dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
2020-11-27T20:11:22 (asr.sh:214:main) ./asr.sh --lang en --use_lm false --token_type char --nbpe 80 --nlsyms_txt data/nlsyms.txt --lm_config conf/train_lm_transformer.yaml --asr_config conf/train_asr_transformer.yaml --inference_config conf/decode.yaml --train_set train_si84 --valid_set test_dev93 --test_sets test_dev93 test_eval92 --bpe_train_text data/train_si284/text --lm_train_text data/train_si284/text data/local/other_text/text --ngpu 1 --feats_type fbank_pitch
2020-11-27T20:11:22 (asr.sh:214:main) ./asr.sh --lang en --use_lm false --token_type char --nbpe 80 --nlsyms_txt data/nlsyms.txt --lm_config conf/train_lm_transformer.yaml --asr_config conf/train_asr_transformer.yaml --inference_config conf/decode.yaml --train_set train_si84 --valid_set test_dev93 --test_sets test_dev93 test_eval92 --bpe_train_text data/train_si284/text --lm_train_text data/train_si284/text data/local/other_text/text --ngpu 1 --feats_type fbank_pitch
2020-11-27T20:11:23 (asr.sh:364:main) Stage 1: Data preparation for data/train_si84, data/test_dev93, etc.
2020-11-27T20:11:23 (data.sh:37:main) local/wsj_data_prep.sh /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_1/??-{?,??}.? /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/??-{?,??}.?
2020-11-27T20:11:23 (asr.sh:364:main) Stage 1: Data preparation for data/train_si84, data/test_dev93, etc.
2020-11-27T20:11:23 (data.sh:37:main) local/wsj_data_prep.sh /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_1/??-{?,??}.? /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/??-{?,??}.?
Data preparation succeeded
2020-11-27T20:11:48 (data.sh:39:main) local/wsj_format_data.sh
local/wsj_format_data.sh 
Data preparation succeeded
2020-11-27T20:11:48 (data.sh:39:main) local/wsj_format_data.sh
local/wsj_format_data.sh 
Preparing train and test data
Preparing train and test data
Succeeded in formatting data.
2020-11-27T20:11:51 (data.sh:43:main) Prepare text from lng_modl dir: /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/13-32.1/wsj1/doc/lng_modl/lm_train/np_data/{87,88,89}/*.z -> data/local/other_text/text
Succeeded in formatting data.
2020-11-27T20:11:51 (data.sh:43:main) Prepare text from lng_modl dir: /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/13-32.1/wsj1/doc/lng_modl/lm_train/np_data/{87,88,89}/*.z -> data/local/other_text/text
2020-11-27T20:12:34 (data.sh:53:main) Create non linguistic symbols: data/nlsyms.txt
2020-11-27T20:12:34 (data.sh:53:main) Create non linguistic symbols: data/nlsyms.txt
<*IN*>
<*MR.*>
<NOISE>
<*IN*>
<*MR.*>
<NOISE>
2020-11-27T20:12:34 (asr.sh:383:main) Skip stage 2: Speed perturbation
2020-11-27T20:12:34 (asr.sh:383:main) Skip stage 2: Speed perturbation
2020-11-27T20:12:34 (asr.sh:429:main) [Require Kaldi] Stage 3: fbank_pitch extract: data/ -> dump/fbank_pitch
2020-11-27T20:12:34 (asr.sh:429:main) [Require Kaldi] Stage 3: fbank_pitch extract: data/ -> dump/fbank_pitch
utils/copy_data_dir.sh: copied data from data/train_si84 to dump/fbank_pitch/org/train_si84
utils/copy_data_dir.sh: copied data from data/train_si84 to dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
2020-11-27T20:14:29 (asr.sh:214:main) ./asr.sh --lang en --use_lm false --token_type char --nbpe 80 --nlsyms_txt data/nlsyms.txt --lm_config conf/train_lm_transformer.yaml --asr_config conf/train_asr_transformer.yaml --inference_config conf/decode.yaml --train_set train_si84 --valid_set test_dev93 --test_sets test_dev93 test_eval92 --bpe_train_text data/train_si284/text --lm_train_text data/train_si284/text data/local/other_text/text --ngpu 1 --feats_type fbank_pitch
2020-11-27T20:14:29 (asr.sh:214:main) ./asr.sh --lang en --use_lm false --token_type char --nbpe 80 --nlsyms_txt data/nlsyms.txt --lm_config conf/train_lm_transformer.yaml --asr_config conf/train_asr_transformer.yaml --inference_config conf/decode.yaml --train_set train_si84 --valid_set test_dev93 --test_sets test_dev93 test_eval92 --bpe_train_text data/train_si284/text --lm_train_text data/train_si284/text data/local/other_text/text --ngpu 1 --feats_type fbank_pitch
2020-11-27T20:14:30 (asr.sh:364:main) Stage 1: Data preparation for data/train_si84, data/test_dev93, etc.
2020-11-27T20:14:30 (asr.sh:364:main) Stage 1: Data preparation for data/train_si84, data/test_dev93, etc.
2020-11-27T20:14:30 (data.sh:37:main) local/wsj_data_prep.sh /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_1/??-{?,??}.? /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/??-{?,??}.?
2020-11-27T20:14:30 (data.sh:37:main) local/wsj_data_prep.sh /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_1/??-{?,??}.? /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/??-{?,??}.?
Data preparation succeeded
2020-11-27T20:14:57 (data.sh:39:main) local/wsj_format_data.sh
local/wsj_format_data.sh 
Data preparation succeeded
2020-11-27T20:14:57 (data.sh:39:main) local/wsj_format_data.sh
local/wsj_format_data.sh 
Preparing train and test data
Preparing train and test data
Succeeded in formatting data.
2020-11-27T20:15:00 (data.sh:43:main) Prepare text from lng_modl dir: /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/13-32.1/wsj1/doc/lng_modl/lm_train/np_data/{87,88,89}/*.z -> data/local/other_text/text
Succeeded in formatting data.
2020-11-27T20:15:00 (data.sh:43:main) Prepare text from lng_modl dir: /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/13-32.1/wsj1/doc/lng_modl/lm_train/np_data/{87,88,89}/*.z -> data/local/other_text/text
2020-11-27T20:15:42 (data.sh:53:main) Create non linguistic symbols: data/nlsyms.txt
2020-11-27T20:15:42 (data.sh:53:main) Create non linguistic symbols: data/nlsyms.txt
<*IN*>
<*MR.*>
<NOISE>
2020-11-27T20:15:43 (asr.sh:383:main) Skip stage 2: Speed perturbation
2020-11-27T20:15:43 (asr.sh:429:main) [Require Kaldi] Stage 3: fbank_pitch extract: data/ -> dump/fbank_pitch
<*IN*>
<*MR.*>
<NOISE>
2020-11-27T20:15:43 (asr.sh:383:main) Skip stage 2: Speed perturbation
2020-11-27T20:15:43 (asr.sh:429:main) [Require Kaldi] Stage 3: fbank_pitch extract: data/ -> dump/fbank_pitch
utils/copy_data_dir.sh: copied data from data/train_si84 to dump/fbank_pitch/org/train_si84
utils/copy_data_dir.sh: copied data from data/train_si84 to dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
2020-11-27T20:17:41 (asr.sh:214:main) ./asr.sh --lang en --use_lm false --token_type char --nbpe 80 --nlsyms_txt data/nlsyms.txt --lm_config conf/train_lm_transformer.yaml --asr_config conf/train_asr_transformer.yaml --inference_config conf/decode.yaml --train_set train_si84 --valid_set test_dev93 --test_sets test_dev93 test_eval92 --bpe_train_text data/train_si284/text --lm_train_text data/train_si284/text data/local/other_text/text --ngpu 1 --feats_type fbank_pitch
steps/make_fbank_pitch.sh: Succeeded creating filterbank and pitch features for train_si84
2020-11-27T20:17:42 (asr.sh:364:main) Stage 1: Data preparation for data/train_si84, data/test_dev93, etc.
2020-11-27T20:17:42 (data.sh:37:main) local/wsj_data_prep.sh /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_1/??-{?,??}.? /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/??-{?,??}.?
fix_data_dir.sh: kept all 7138 utterances.
fix_data_dir.sh: old files are kept in dump/fbank_pitch/org/train_si84/.backup
utils/copy_data_dir.sh: copied data from data/test_dev93 to dump/fbank_pitch/org/test_dev93
utils/copy_data_dir.sh: file feats.scp exists in dest dump/fbank_pitch/org/test_dev93 but not in src data/test_dev93.  Moving it to
 ... dump/fbank_pitch/org/test_dev93/.backup/feats.scp
utils/copy_data_dir.sh: file utt2dur exists in dest dump/fbank_pitch/org/test_dev93 but not in src data/test_dev93.  Moving it to
 ... dump/fbank_pitch/org/test_dev93/.backup/utt2dur
utils/copy_data_dir.sh: file utt2num_frames exists in dest dump/fbank_pitch/org/test_dev93 but not in src data/test_dev93.  Moving it to
 ... dump/fbank_pitch/org/test_dev93/.backup/utt2num_frames
utils/copy_data_dir.sh: file frame_shift exists in dest dump/fbank_pitch/org/test_dev93 but not in src data/test_dev93.  Moving it to
 ... dump/fbank_pitch/org/test_dev93/.backup/frame_shift
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/test_dev93
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/test_dev93
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/test_dev93
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_fbank_pitch.sh: Succeeded creating filterbank and pitch features for test_dev93
fix_data_dir.sh: kept all 503 utterances.
fix_data_dir.sh: old files are kept in dump/fbank_pitch/org/test_dev93/.backup
utils/copy_data_dir.sh: copied data from data/test_dev93 to dump/fbank_pitch/org/test_dev93
utils/copy_data_dir.sh: file feats.scp exists in dest dump/fbank_pitch/org/test_dev93 but not in src data/test_dev93.  Moving it to
 ... dump/fbank_pitch/org/test_dev93/.backup/feats.scp
utils/copy_data_dir.sh: file utt2dur exists in dest dump/fbank_pitch/org/test_dev93 but not in src data/test_dev93.  Moving it to
 ... dump/fbank_pitch/org/test_dev93/.backup/utt2dur
utils/copy_data_dir.sh: file utt2num_frames exists in dest dump/fbank_pitch/org/test_dev93 but not in src data/test_dev93.  Moving it to
 ... dump/fbank_pitch/org/test_dev93/.backup/utt2num_frames
utils/copy_data_dir.sh: file frame_shift exists in dest dump/fbank_pitch/org/test_dev93 but not in src data/test_dev93.  Moving it to
 ... dump/fbank_pitch/org/test_dev93/.backup/frame_shift
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/test_dev93
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/test_dev93
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/test_dev93
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_fbank_pitch.sh: Succeeded creating filterbank and pitch features for test_dev93
fix_data_dir.sh: kept all 503 utterances.
fix_data_dir.sh: old files are kept in dump/fbank_pitch/org/test_dev93/.backup
Data preparation succeeded
2020-11-27T20:18:19 (data.sh:39:main) local/wsj_format_data.sh
local/wsj_format_data.sh 
utils/copy_data_dir.sh: copied data from data/test_eval92 to dump/fbank_pitch/test_eval92
utils/copy_data_dir.sh: file feats.scp exists in dest dump/fbank_pitch/test_eval92 but not in src data/test_eval92.  Moving it to
 ... dump/fbank_pitch/test_eval92/.backup/feats.scp
utils/copy_data_dir.sh: file utt2dur exists in dest dump/fbank_pitch/test_eval92 but not in src data/test_eval92.  Moving it to
 ... dump/fbank_pitch/test_eval92/.backup/utt2dur
utils/copy_data_dir.sh: file utt2num_frames exists in dest dump/fbank_pitch/test_eval92 but not in src data/test_eval92.  Moving it to
 ... dump/fbank_pitch/test_eval92/.backup/utt2num_frames
utils/copy_data_dir.sh: file frame_shift exists in dest dump/fbank_pitch/test_eval92 but not in src data/test_eval92.  Moving it to
 ... dump/fbank_pitch/test_eval92/.backup/frame_shift
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/test_eval92
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/test_eval92
Preparing train and test data
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/test_eval92
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
Succeeded in formatting data.
2020-11-27T20:18:21 (data.sh:43:main) Prepare text from lng_modl dir: /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/13-32.1/wsj1/doc/lng_modl/lm_train/np_data/{87,88,89}/*.z -> data/local/other_text/text
steps/make_fbank_pitch.sh: Succeeded creating filterbank and pitch features for test_eval92
fix_data_dir.sh: kept all 333 utterances.
fix_data_dir.sh: old files are kept in dump/fbank_pitch/test_eval92/.backup
2020-11-27T20:18:36 (asr.sh:490:main) Stage 4: Remove long/short data: dump/fbank_pitch/org -> dump/fbank_pitch
utils/copy_data_dir.sh: copied data from dump/fbank_pitch/org/train_si84 to dump/fbank_pitch/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/train_si84
fix_data_dir.sh: kept 7137 utterances out of 7138
fix_data_dir.sh: old files are kept in dump/fbank_pitch/train_si84/.backup
utils/copy_data_dir.sh: copied data from dump/fbank_pitch/org/test_dev93 to dump/fbank_pitch/test_dev93
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/test_dev93
fix_data_dir.sh: kept all 503 utterances.
fix_data_dir.sh: old files are kept in dump/fbank_pitch/test_dev93/.backup
2020-11-27T20:19:03 (data.sh:53:main) Create non linguistic symbols: data/nlsyms.txt
<*IN*>
<*MR.*>
<NOISE>
2020-11-27T20:19:04 (asr.sh:383:main) Skip stage 2: Speed perturbation
2020-11-27T20:19:04 (asr.sh:429:main) [Require Kaldi] Stage 3: fbank_pitch extract: data/ -> dump/fbank_pitch
utils/copy_data_dir.sh: copied data from data/train_si84 to dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
2020-11-27T20:19:26 (asr.sh:585:main) Stage 5: Generate character level token_list from data/train_si284/text data/local/other_text/text
2020-11-27T20:19:54 (asr.sh:214:main) ./asr.sh --lang en --use_lm false --token_type char --nbpe 80 --nlsyms_txt data/nlsyms.txt --lm_config conf/train_lm_transformer.yaml --asr_config conf/train_asr_transformer.yaml --inference_config conf/decode.yaml --train_set train_si84 --valid_set test_dev93 --test_sets test_dev93 test_eval92 --bpe_train_text data/train_si284/text --lm_train_text data/train_si284/text data/local/other_text/text --ngpu 1 --feats_type fbank_pitch
2020-11-27T20:19:54 (asr.sh:364:main) Stage 1: Data preparation for data/train_si84, data/test_dev93, etc.
2020-11-27T20:19:54 (data.sh:37:main) local/wsj_data_prep.sh /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_1/??-{?,??}.? /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/??-{?,??}.?
Data preparation succeeded
2020-11-27T20:20:10 (data.sh:39:main) local/wsj_format_data.sh
local/wsj_format_data.sh 
Preparing train and test data
Succeeded in formatting data.
2020-11-27T20:20:12 (data.sh:43:main) Prepare text from lng_modl dir: /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/13-32.1/wsj1/doc/lng_modl/lm_train/np_data/{87,88,89}/*.z -> data/local/other_text/text
2020-11-27T20:20:38 (data.sh:53:main) Create non linguistic symbols: data/nlsyms.txt
<*IN*>
<*MR.*>
<NOISE>
2020-11-27T20:20:38 (asr.sh:383:main) Skip stage 2: Speed perturbation
2020-11-27T20:20:38 (asr.sh:429:main) [Require Kaldi] Stage 3: fbank_pitch extract: data/ -> dump/fbank_pitch
utils/copy_data_dir.sh: copied data from data/train_si84 to dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
2020-11-27T20:20:43 (asr.sh:214:main) ./asr.sh --lang en --use_lm false --token_type char --nbpe 80 --nlsyms_txt data/nlsyms.txt --lm_config conf/train_lm_transformer.yaml --asr_config conf/train_asr_transformer.yaml --inference_config conf/decode.yaml --train_set train_si84 --valid_set test_dev93 --test_sets test_dev93 test_eval92 --bpe_train_text data/train_si284/text --lm_train_text data/train_si284/text data/local/other_text/text --ngpu 1 --feats_type fbank_pitch
2020-11-27T20:20:44 (asr.sh:364:main) Stage 1: Data preparation for data/train_si84, data/test_dev93, etc.
2020-11-27T20:20:44 (data.sh:37:main) local/wsj_data_prep.sh /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_1/??-{?,??}.? /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/??-{?,??}.?
Data preparation succeeded
2020-11-27T20:20:59 (data.sh:39:main) local/wsj_format_data.sh
local/wsj_format_data.sh 
Preparing train and test data
Succeeded in formatting data.
2020-11-27T20:21:01 (data.sh:43:main) Prepare text from lng_modl dir: /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/13-32.1/wsj1/doc/lng_modl/lm_train/np_data/{87,88,89}/*.z -> data/local/other_text/text
2020-11-27T20:21:27 (data.sh:53:main) Create non linguistic symbols: data/nlsyms.txt
<*IN*>
<*MR.*>
<NOISE>
2020-11-27T20:21:28 (asr.sh:383:main) Skip stage 2: Speed perturbation
2020-11-27T20:21:28 (asr.sh:429:main) [Require Kaldi] Stage 3: fbank_pitch extract: data/ -> dump/fbank_pitch
utils/copy_data_dir.sh: copied data from data/train_si84 to dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
2020-11-27T20:21:33 (asr.sh:214:main) ./asr.sh --lang en --use_lm false --token_type char --nbpe 80 --nlsyms_txt data/nlsyms.txt --lm_config conf/train_lm_transformer.yaml --asr_config conf/train_asr_transformer.yaml --inference_config conf/decode.yaml --train_set train_si84 --valid_set test_dev93 --test_sets test_dev93 test_eval92 --bpe_train_text data/train_si284/text --lm_train_text data/train_si284/text data/local/other_text/text --ngpu 1 --feats_type fbank_pitch
2020-11-27T20:21:33 (asr.sh:364:main) Stage 1: Data preparation for data/train_si84, data/test_dev93, etc.
2020-11-27T20:21:33 (data.sh:37:main) local/wsj_data_prep.sh /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_1/??-{?,??}.? /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/??-{?,??}.?
Data preparation succeeded
2020-11-27T20:21:49 (data.sh:39:main) local/wsj_format_data.sh
local/wsj_format_data.sh 
Preparing train and test data
Succeeded in formatting data.
2020-11-27T20:21:51 (data.sh:43:main) Prepare text from lng_modl dir: /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/13-32.1/wsj1/doc/lng_modl/lm_train/np_data/{87,88,89}/*.z -> data/local/other_text/text
2020-11-27T20:22:17 (data.sh:53:main) Create non linguistic symbols: data/nlsyms.txt
<*IN*>
<*MR.*>
<NOISE>
2020-11-27T20:22:17 (asr.sh:383:main) Skip stage 2: Speed perturbation
2020-11-27T20:22:17 (asr.sh:429:main) [Require Kaldi] Stage 3: fbank_pitch extract: data/ -> dump/fbank_pitch
utils/copy_data_dir.sh: copied data from data/train_si84 to dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
2020-11-27T20:23:09 (asr.sh:806:main) Stage 6-8: Skip lm-related stages: use_lm=false
2020-11-27T20:23:09 (asr.sh:813:main) Stage 9: ASR collect stats: train_set=dump/fbank_pitch/train_si84, valid_set=dump/fbank_pitch/test_dev93
2020-11-27T20:23:11 (asr.sh:863:main) Generate 'exp/asr_stats_fbank_pitch_char/run.sh'. You can resume the process from stage 9 using this script
2020-11-27T20:23:12 (asr.sh:867:main) ASR collect-stats started... log: 'exp/asr_stats_fbank_pitch_char/logdir/stats.*.log'
2020-11-27T20:23:13 (asr.sh:214:main) ./asr.sh --lang en --use_lm false --token_type char --nbpe 80 --nlsyms_txt data/nlsyms.txt --lm_config conf/train_lm_transformer.yaml --asr_config conf/train_asr_transformer.yaml --inference_config conf/decode.yaml --train_set train_si84 --valid_set test_dev93 --test_sets test_dev93 test_eval92 --bpe_train_text data/train_si284/text --lm_train_text data/train_si284/text data/local/other_text/text --ngpu 1 --feats_type fbank_pitch
2020-11-27T20:23:14 (asr.sh:364:main) Stage 1: Data preparation for data/train_si84, data/test_dev93, etc.
2020-11-27T20:23:14 (data.sh:37:main) local/wsj_data_prep.sh /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_1/??-{?,??}.? /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/??-{?,??}.?
Data preparation succeeded
2020-11-27T20:23:43 (data.sh:39:main) local/wsj_format_data.sh
local/wsj_format_data.sh 
Preparing train and test data
Succeeded in formatting data.
2020-11-27T20:23:46 (data.sh:43:main) Prepare text from lng_modl dir: /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/13-32.1/wsj1/doc/lng_modl/lm_train/np_data/{87,88,89}/*.z -> data/local/other_text/text
2020-11-27T20:24:04 (asr.sh:914:main) Stage 10: ASR Training: train_set=dump/fbank_pitch/train_si84, valid_set=dump/fbank_pitch/test_dev93
2020-11-27T20:24:04 (asr.sh:981:main) Generate 'exp/asr_train_asr_transformer_fbank_pitch_char/run.sh'. You can resume the process from stage 10 using this script
2020-11-27T20:24:04 (asr.sh:985:main) ASR training started... log: 'exp/asr_train_asr_transformer_fbank_pitch_char/train.log'
2020-11-27T20:24:15 (data.sh:53:main) Create non linguistic symbols: data/nlsyms.txt
<*IN*>
<*MR.*>
<NOISE>
2020-11-27T20:24:16 (asr.sh:383:main) Skip stage 2: Speed perturbation
2020-11-27T20:24:16 (asr.sh:429:main) [Require Kaldi] Stage 3: fbank_pitch extract: data/ -> dump/fbank_pitch
utils/copy_data_dir.sh: copied data from data/train_si84 to dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
2020-11-27T20:25:05 (asr.sh:214:main) ./asr.sh --lang en --use_lm false --token_type char --nbpe 80 --nlsyms_txt data/nlsyms.txt --lm_config conf/train_lm_transformer.yaml --asr_config conf/train_asr_transformer.yaml --inference_config conf/decode.yaml --train_set train_si84 --valid_set test_dev93 --test_sets test_dev93 test_eval92 --bpe_train_text data/train_si284/text --lm_train_text data/train_si284/text data/local/other_text/text --ngpu 1 --feats_type fbank_pitch
2020-11-27T20:25:06 (asr.sh:364:main) Stage 1: Data preparation for data/train_si84, data/test_dev93, etc.
2020-11-27T20:25:06 (data.sh:37:main) local/wsj_data_prep.sh /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_1/??-{?,??}.? /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/??-{?,??}.?
(2_w,4mirr1)-aCMA-ES (mu_w=1.5,w_1=80%) in dimension 3 (seed=668222, Fri Nov 27 20:01:49 2020)
RUNNING:-dup


RUNNING:


run.pl: 32 / 32 failed, log is in dump/fbank_pitch/org/train_si84/log/make_fbank_pitch_train_si84.*.log

Failed a run
RUNNING:-dup


run.pl: 32 / 32 failed, log is in dump/fbank_pitch/org/train_si84/log/make_fbank_pitch_train_si84.*.log

Failed a run
RUNNING:


run.pl: 32 / 32 failed, log is in dump/fbank_pitch/org/train_si84/log/make_fbank_pitch_train_si84.*.log

Failed a run
RUNNING:-dup


run.pl: 32 / 32 failed, log is in dump/fbank_pitch/org/train_si84/log/make_fbank_pitch_train_si84.*.log

Failed a run
RUNNING:


run.pl: 32 / 32 failed, log is in dump/fbank_pitch/org/train_si84/log/make_fbank_pitch_train_si84.*.log

Failed a run
RUNNING:-dup


run.pl: 32 / 32 failed, log is in dump/fbank_pitch/org/train_si84/log/make_fbank_pitch_train_si84.*.log

Failed a run
RUNNING:


run.pl: 32 / 32 failed, log is in dump/fbank_pitch/org/train_si84/log/make_fbank_pitch_train_si84.*.log

Failed a run
RUNNING:-dup


run.pl: 32 / 32 failed, log is in dump/fbank_pitch/org/train_si84/log/make_fbank_pitch_train_si84.*.log

Failed a run
RUNNING:


run.pl: 32 / 32 failed, log is in dump/fbank_pitch/org/train_si84/log/make_fbank_pitch_train_si84.*.log

Failed a run
RUNNING:-dup


run.pl: 32 / 32 failed, log is in dump/fbank_pitch/org/train_si84/log/make_fbank_pitch_train_si84.*.log

Failed a run
RUNNING:-dup


run.pl: 32 / 32 failed, log is in dump/fbank_pitch/org/train_si84/log/make_fbank_pitch_train_si84.*.log

Failed a run
RUNNING:-dup


run.pl: 32 / 32 failed, log is in dump/fbank_pitch/org/train_si84/log/make_fbank_pitch_train_si84.*.log

Failed a run
RUNNING:-dup


run.pl: 32 / 32 failed, log is in dump/fbank_pitch/org/train_si84/log/make_fbank_pitch_train_si84.*.log

Failed a run
RUNNING:-dup


run.pl: 32 / 32 failed, log is in dump/fbank_pitch/org/train_si84/log/make_fbank_pitch_train_si84.*.log

Failed a run
RUNNING:-dup


scripts/feats/feat_to_shape.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/train_si84/feats.scp dump/fbank_pitch/org/train_si84/feats_shape
scripts/feats/feat_to_shape.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/test_dev93/feats.scp dump/fbank_pitch/org/test_dev93/feats_shape
scripts/feats/feat_to_shape.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/test_dev93/feats.scp dump/fbank_pitch/org/test_dev93/feats_shape
scripts/feats/feat_to_shape.sh --nj 32 --cmd run.pl dump/fbank_pitch/test_eval92/feats.scp dump/fbank_pitch/test_eval92/feats_shape
/afs/cs.pitt.edu/usr0/ras306/miniconda3/envs/psinet/bin/python3 /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/bin/tokenize_text.py --token_type char --input dump/fbank_pitch/lm_train.txt --output data/token_list/char/tokens.txt --non_linguistic_symbols data/nlsyms.txt --field 2- --cleaner none --g2p none --write_vocabulary true --add_symbol '<blank>:0' --add_symbol '<unk>:1' --add_symbol '<sos/eos>:-1'
2020-11-27 20:23:09,339 (tokenize_text:171) INFO: OOV rate = 0.0 %
/afs/cs.pitt.edu/usr0/ras306/miniconda3/envs/psinet/bin/python3 /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/bin/aggregate_stats_dirs.py --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.1 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.2 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.3 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.4 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.5 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.6 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.7 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.8 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.9 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.10 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.11 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.12 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.13 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.14 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.15 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.16 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.17 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.18 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.19 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.20 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.21 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.22 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.23 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.24 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.25 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.26 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.27 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.28 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.29 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.30 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.31 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.32 --output_dir exp/asr_stats_fbank_pitch_char
2020-11-27 20:24:05,203 (launch:95) INFO: /afs/cs.pitt.edu/usr0/ras306/miniconda3/envs/psinet/bin/python3 /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/bin/launch.py --cmd 'run.pl --name exp/asr_train_asr_transformer_fbank_pitch_char/train.log' --log exp/asr_train_asr_transformer_fbank_pitch_char/train.log --ngpu 1 --num_nodes 1 --init_file_prefix exp/asr_train_asr_transformer_fbank_pitch_char/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel none --token_type char --token_list data/token_list/char/tokens.txt --non_linguistic_symbols data/nlsyms.txt --cleaner none --g2p none --valid_data_path_and_name_and_type dump/fbank_pitch/test_dev93/feats.scp,speech,kaldi_ark --valid_data_path_and_name_and_type dump/fbank_pitch/test_dev93/text,text,text --valid_shape_file exp/asr_stats_fbank_pitch_char/valid/speech_shape --valid_shape_file exp/asr_stats_fbank_pitch_char/valid/text_shape.char --resume true --fold_length 800 --fold_length 150 --output_dir exp/asr_train_asr_transformer_fbank_pitch_char --config conf/train_asr_transformer.yaml --input_size=58 --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_fbank_pitch_char/train/feats_stats.npz --train_data_path_and_name_and_type dump/fbank_pitch/train_si84/feats.scp,speech,kaldi_ark --train_data_path_and_name_and_type dump/fbank_pitch/train_si84/text,text,text --train_shape_file exp/asr_stats_fbank_pitch_char/train/speech_shape --train_shape_file exp/asr_stats_fbank_pitch_char/train/text_shape.char
2020-11-27 20:24:05,423 (launch:349) INFO: log file: exp/asr_train_asr_transformer_fbank_pitch_char/train.log
run.pl: job failed, log is in exp/asr_train_asr_transformer_fbank_pitch_char/train.log
Command '['run.pl', '--name', 'exp/asr_train_asr_transformer_fbank_pitch_char/train.log', '--gpu', '1', 'exp/asr_train_asr_transformer_fbank_pitch_char/train.log', 'python3', '-m', 'espnet2.bin.asr_train', '--use_preprocessor', 'true', '--bpemodel', 'none', '--token_type', 'char', '--token_list', 'data/token_list/char/tokens.txt', '--non_linguistic_symbols', 'data/nlsyms.txt', '--cleaner', 'none', '--g2p', 'none', '--valid_data_path_and_name_and_type', 'dump/fbank_pitch/test_dev93/feats.scp,speech,kaldi_ark', '--valid_data_path_and_name_and_type', 'dump/fbank_pitch/test_dev93/text,text,text', '--valid_shape_file', 'exp/asr_stats_fbank_pitch_char/valid/speech_shape', '--valid_shape_file', 'exp/asr_stats_fbank_pitch_char/valid/text_shape.char', '--resume', 'true', '--fold_length', '800', '--fold_length', '150', '--output_dir', 'exp/asr_train_asr_transformer_fbank_pitch_char', '--config', 'conf/train_asr_transformer.yaml', '--input_size=58', '--normalize=global_mvn', '--normalize_conf', 'stats_file=exp/asr_stats_fbank_pitch_char/train/feats_stats.npz', '--train_data_path_and_name_and_type', 'dump/fbank_pitch/train_si84/feats.scp,speech,kaldi_ark', '--train_data_path_and_name_and_type', 'dump/fbank_pitch/train_si84/text,text,text', '--train_shape_file', 'exp/asr_stats_fbank_pitch_char/train/speech_shape', '--train_shape_file', 'exp/asr_stats_fbank_pitch_char/train/text_shape.char', '--ngpu', '1', '--multiprocessing_distributed', 'True']' returned non-zero exit status 1.
Traceback (most recent call last):
  File "/afs/cs.pitt.edu/usr0/ras306/miniconda3/envs/psinet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/afs/cs.pitt.edu/usr0/ras306/miniconda3/envs/psinet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/bin/launch.py", line 385, in <module>
    main()
  File "/afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/bin/launch.py", line 378, in main
    f"###################\n" + "".join(lines[-1000:])
RuntimeError: 
################### The last 1000 lines of exp/asr_train_asr_transformer_fbank_pitch_char/train.log ###################
# python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel none --token_type char --token_list data/token_list/char/tokens.txt --non_linguistic_symbols data/nlsyms.txt --cleaner none --g2p none --valid_data_path_and_name_and_type dump/fbank_pitch/test_dev93/feats.scp,speech,kaldi_ark --valid_data_path_and_name_and_type dump/fbank_pitch/test_dev93/text,text,text --valid_shape_file exp/asr_stats_fbank_pitch_char/valid/speech_shape --valid_shape_file exp/asr_stats_fbank_pitch_char/valid/text_shape.char --resume true --fold_length 800 --fold_length 150 --output_dir exp/asr_train_asr_transformer_fbank_pitch_char --config conf/train_asr_transformer.yaml --input_size=58 --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_fbank_pitch_char/train/feats_stats.npz --train_data_path_and_name_and_type dump/fbank_pitch/train_si84/feats.scp,speech,kaldi_ark --train_data_path_and_name_and_type dump/fbank_pitch/train_si84/text,text,text --train_shape_file exp/asr_stats_fbank_pitch_char/train/speech_shape --train_shape_file exp/asr_stats_fbank_pitch_char/train/text_shape.char --ngpu 1 --multiprocessing_distributed True 
# Started at Fri Nov 27 20:24:05 EST 2020
#
/afs/cs.pitt.edu/usr0/ras306/miniconda3/envs/psinet/bin/python3 /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/bin/asr_train.py --use_preprocessor true --bpemodel none --token_type char --token_list data/token_list/char/tokens.txt --non_linguistic_symbols data/nlsyms.txt --cleaner none --g2p none --valid_data_path_and_name_and_type dump/fbank_pitch/test_dev93/feats.scp,speech,kaldi_ark --valid_data_path_and_name_and_type dump/fbank_pitch/test_dev93/text,text,text --valid_shape_file exp/asr_stats_fbank_pitch_char/valid/speech_shape --valid_shape_file exp/asr_stats_fbank_pitch_char/valid/text_shape.char --resume true --fold_length 800 --fold_length 150 --output_dir exp/asr_train_asr_transformer_fbank_pitch_char --config conf/train_asr_transformer.yaml --input_size=58 --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_fbank_pitch_char/train/feats_stats.npz --train_data_path_and_name_and_type dump/fbank_pitch/train_si84/feats.scp,speech,kaldi_ark --train_data_path_and_name_and_type dump/fbank_pitch/train_si84/text,text,text --train_shape_file exp/asr_stats_fbank_pitch_char/train/speech_shape --train_shape_file exp/asr_stats_fbank_pitch_char/train/text_shape.char --ngpu 1 --multiprocessing_distributed True
[magnolia] 2020-11-27 20:24:09,047 (asr:283) INFO: Vocabulary size: 65
[magnolia] 2020-11-27 20:24:57,913 (abs_task:1068) INFO: pytorch.version=1.4.0, cuda.available=True, cudnn.version=7603, cudnn.benchmark=False, cudnn.deterministic=True
[magnolia] 2020-11-27 20:24:57,923 (abs_task:1069) INFO: Model structure:
ESPnetASRModel(
  (normalize): GlobalMVN(stats_file=exp/asr_stats_fbank_pitch_char/train/feats_stats.npz, norm_means=True, norm_vars=True)
  (encoder): TransformerEncoder(
    (embed): Conv2dSubsampling(
      (conv): Sequential(
        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=3328, out_features=256, bias=True)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (encoders): MultiSequential(
      (0): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (2): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (3): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (4): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (5): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (6): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (7): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (8): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (9): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (10): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (11): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (embed): Sequential(
      (0): Embedding(65, 256)
      (1): PositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
    (output_layer): Linear(in_features=256, out_features=65, bias=True)
    (decoders): MultiSequential(
      (0): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (2): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (3): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (4): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (5): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=256, out_features=65, bias=True)
    (ctc_loss): CTCLoss()
  )
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
)

Model summary:
    Class Name: ESPnetASRModel
    Number of parameters: 26.75 M
    Size: 107 MB
    Type: torch.float32
[magnolia] 2020-11-27 20:24:57,924 (abs_task:1072) INFO: Optimizer:
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.005
    lr: 1.6666666666666665e-07
    weight_decay: 0
)
[magnolia] 2020-11-27 20:24:57,924 (abs_task:1073) INFO: Scheduler: WarmupLR(warmup_steps=30000)
[magnolia] 2020-11-27 20:24:57,929 (abs_task:1083) INFO: Saving the configuration in exp/asr_train_asr_transformer_fbank_pitch_char/config.yaml
Traceback (most recent call last):
  File "/afs/cs.pitt.edu/usr0/ras306/miniconda3/envs/psinet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/afs/cs.pitt.edu/usr0/ras306/miniconda3/envs/psinet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/bin/asr_train.py", line 23, in <module>
    main()
  File "/afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/bin/asr_train.py", line 19, in main
    ASRTask.main(cmd=cmd)
  File "/afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/tasks/abs_task.py", line 941, in main
    cls.main_worker(args)
  File "/afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/tasks/abs_task.py", line 1122, in main_worker
    ngpu=args.ngpu,
  File "/afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/tasks/abs_task.py", line 899, in resume
    model.load_state_dict(states["model"])
  File "/afs/cs.pitt.edu/usr0/ras306/miniconda3/envs/psinet/lib/python3.7/site-packages/torch/nn/modules/module.py", line 830, in load_state_dict
    self.__class__.__name__, "\n\t".join(error_msgs)))
RuntimeError: Error(s) in loading state_dict for ESPnetASRModel:
	size mismatch for normalize.mean: copying a param with shape torch.Size([26]) from checkpoint, the shape in current model is torch.Size([58]).
	size mismatch for normalize.std: copying a param with shape torch.Size([26]) from checkpoint, the shape in current model is torch.Size([58]).
	size mismatch for encoder.embed.out.0.weight: copying a param with shape torch.Size([256, 1280]) from checkpoint, the shape in current model is torch.Size([256, 3328]).
# Accounting: time=90 threads=1
# Ended (code 1) at Fri Nov 27 20:25:35 EST 2020, elapsed time 90 seconds

2020-11-27T20:25:35 (asr.sh:214:main) ./asr.sh --lang en --use_lm false --token_type char --nbpe 80 --nlsyms_txt data/nlsyms.txt --lm_config conf/train_lm_transformer.yaml --asr_config conf/train_asr_transformer.yaml --inference_config conf/decode.yaml --train_set train_si84 --valid_set test_dev93 --test_sets test_dev93 test_eval92 --bpe_train_text data/train_si284/text --lm_train_text data/train_si284/text data/local/other_text/text --ngpu 1 --feats_type fbank_pitch
Data preparation succeeded
2020-11-27T20:25:36 (data.sh:39:main) local/wsj_format_data.sh
local/wsj_format_data.sh 
2020-11-27T20:25:36 (asr.sh:364:main) Stage 1: Data preparation for data/train_si84, data/test_dev93, etc.
Preparing train and test data
2020-11-27T20:25:36 (data.sh:37:main) local/wsj_data_prep.sh /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_1/??-{?,??}.? /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/??-{?,??}.?
Succeeded in formatting data.
2020-11-27T20:25:38 (data.sh:43:main) Prepare text from lng_modl dir: /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/13-32.1/wsj1/doc/lng_modl/lm_train/np_data/{87,88,89}/*.z -> data/local/other_text/text
2020-11-27T20:26:05 (data.sh:53:main) Create non linguistic symbols: data/nlsyms.txt
<*IN*>
<*MR.*>
<NOISE>
2020-11-27T20:26:05 (asr.sh:383:main) Skip stage 2: Speed perturbation
2020-11-27T20:26:05 (asr.sh:429:main) [Require Kaldi] Stage 3: fbank_pitch extract: data/ -> dump/fbank_pitch
utils/copy_data_dir.sh: copied data from data/train_si84 to dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
Data preparation succeeded
2020-11-27T20:26:21 (data.sh:39:main) local/wsj_format_data.sh
local/wsj_format_data.sh 
Preparing train and test data
Succeeded in formatting data.
2020-11-27T20:26:37 (data.sh:43:main) Prepare text from lng_modl dir: /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/13-32.1/wsj1/doc/lng_modl/lm_train/np_data/{87,88,89}/*.z -> data/local/other_text/text
2020-11-27T20:27:03 (asr.sh:214:main) ./asr.sh --lang en --use_lm false --token_type char --nbpe 80 --nlsyms_txt data/nlsyms.txt --lm_config conf/train_lm_transformer.yaml --asr_config conf/train_asr_transformer.yaml --inference_config conf/decode.yaml --train_set train_si84 --valid_set test_dev93 --test_sets test_dev93 test_eval92 --bpe_train_text data/train_si284/text --lm_train_text data/train_si284/text data/local/other_text/text --ngpu 1 --feats_type fbank_pitch
2020-11-27T20:27:04 (asr.sh:364:main) Stage 1: Data preparation for data/train_si84, data/test_dev93, etc.
2020-11-27T20:27:04 (data.sh:37:main) local/wsj_data_prep.sh /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_1/??-{?,??}.? /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/??-{?,??}.?
2020-11-27T20:27:17 (data.sh:53:main) Create non linguistic symbols: data/nlsyms.txt
<*IN*>
<*MR.*>
<NOISE>
2020-11-27T20:27:17 (asr.sh:383:main) Skip stage 2: Speed perturbation
2020-11-27T20:27:18 (asr.sh:429:main) [Require Kaldi] Stage 3: fbank_pitch extract: data/ -> dump/fbank_pitch
utils/copy_data_dir.sh: copied data from data/train_si84 to dump/fbank_pitch/org/train_si84
utils/copy_data_dir.sh: file feats.scp exists in dest dump/fbank_pitch/org/train_si84 but not in src data/train_si84.  Moving it to
 ... dump/fbank_pitch/org/train_si84/.backup/feats.scp
utils/copy_data_dir.sh: file utt2dur exists in dest dump/fbank_pitch/org/train_si84 but not in src data/train_si84.  Moving it to
 ... dump/fbank_pitch/org/train_si84/.backup/utt2dur
utils/copy_data_dir.sh: file utt2num_frames exists in dest dump/fbank_pitch/org/train_si84 but not in src data/train_si84.  Moving it to
 ... dump/fbank_pitch/org/train_si84/.backup/utt2num_frames
utils/copy_data_dir.sh: file frame_shift exists in dest dump/fbank_pitch/org/train_si84 but not in src data/train_si84.  Moving it to
 ... dump/fbank_pitch/org/train_si84/.backup/frame_shift
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_fbank_pitch.sh: Succeeded creating filterbank and pitch features for train_si84
fix_data_dir.sh: kept all 7138 utterances.
fix_data_dir.sh: old files are kept in dump/fbank_pitch/org/train_si84/.backup
utils/copy_data_dir.sh: copied data from data/test_dev93 to dump/fbank_pitch/org/test_dev93
utils/copy_data_dir.sh: file feats.scp exists in dest dump/fbank_pitch/org/test_dev93 but not in src data/test_dev93.  Moving it to
 ... dump/fbank_pitch/org/test_dev93/.backup/feats.scp
utils/copy_data_dir.sh: file utt2dur exists in dest dump/fbank_pitch/org/test_dev93 but not in src data/test_dev93.  Moving it to
 ... dump/fbank_pitch/org/test_dev93/.backup/utt2dur
utils/copy_data_dir.sh: file utt2num_frames exists in dest dump/fbank_pitch/org/test_dev93 but not in src data/test_dev93.  Moving it to
 ... dump/fbank_pitch/org/test_dev93/.backup/utt2num_frames
utils/copy_data_dir.sh: file frame_shift exists in dest dump/fbank_pitch/org/test_dev93 but not in src data/test_dev93.  Moving it to
 ... dump/fbank_pitch/org/test_dev93/.backup/frame_shift
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/test_dev93
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/test_dev93
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/test_dev93
Data preparation succeeded
2020-11-27T20:28:35 (data.sh:39:main) local/wsj_format_data.sh
local/wsj_format_data.sh 
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
Preparing train and test data
Succeeded in formatting data.
2020-11-27T20:28:44 (data.sh:43:main) Prepare text from lng_modl dir: /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/13-32.1/wsj1/doc/lng_modl/lm_train/np_data/{87,88,89}/*.z -> data/local/other_text/text
steps/make_fbank_pitch.sh: Succeeded creating filterbank and pitch features for test_dev93
fix_data_dir.sh: kept all 503 utterances.
fix_data_dir.sh: old files are kept in dump/fbank_pitch/org/test_dev93/.backup
utils/copy_data_dir.sh: copied data from data/test_dev93 to dump/fbank_pitch/org/test_dev93
utils/copy_data_dir.sh: file feats.scp exists in dest dump/fbank_pitch/org/test_dev93 but not in src data/test_dev93.  Moving it to
 ... dump/fbank_pitch/org/test_dev93/.backup/feats.scp
utils/copy_data_dir.sh: file utt2dur exists in dest dump/fbank_pitch/org/test_dev93 but not in src data/test_dev93.  Moving it to
 ... dump/fbank_pitch/org/test_dev93/.backup/utt2dur
utils/copy_data_dir.sh: file utt2num_frames exists in dest dump/fbank_pitch/org/test_dev93 but not in src data/test_dev93.  Moving it to
 ... dump/fbank_pitch/org/test_dev93/.backup/utt2num_frames
utils/copy_data_dir.sh: file frame_shift exists in dest dump/fbank_pitch/org/test_dev93 but not in src data/test_dev93.  Moving it to
 ... dump/fbank_pitch/org/test_dev93/.backup/frame_shift
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/test_dev93
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/test_dev93
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/test_dev93
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_fbank_pitch.sh: Succeeded creating filterbank and pitch features for test_dev93
fix_data_dir.sh: kept all 503 utterances.
fix_data_dir.sh: old files are kept in dump/fbank_pitch/org/test_dev93/.backup
utils/copy_data_dir.sh: copied data from data/test_eval92 to dump/fbank_pitch/test_eval92
utils/copy_data_dir.sh: file feats.scp exists in dest dump/fbank_pitch/test_eval92 but not in src data/test_eval92.  Moving it to
 ... dump/fbank_pitch/test_eval92/.backup/feats.scp
utils/copy_data_dir.sh: file utt2dur exists in dest dump/fbank_pitch/test_eval92 but not in src data/test_eval92.  Moving it to
 ... dump/fbank_pitch/test_eval92/.backup/utt2dur
utils/copy_data_dir.sh: file utt2num_frames exists in dest dump/fbank_pitch/test_eval92 but not in src data/test_eval92.  Moving it to
 ... dump/fbank_pitch/test_eval92/.backup/utt2num_frames
utils/copy_data_dir.sh: file frame_shift exists in dest dump/fbank_pitch/test_eval92 but not in src data/test_eval92.  Moving it to
 ... dump/fbank_pitch/test_eval92/.backup/frame_shift
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/test_eval92
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/test_eval92
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/test_eval92
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
2020-11-27T20:29:17 (data.sh:53:main) Create non linguistic symbols: data/nlsyms.txt
steps/make_fbank_pitch.sh: Succeeded creating filterbank and pitch features for test_eval92
<*IN*>
<*MR.*>
<NOISE>
2020-11-27T20:29:18 (asr.sh:383:main) Skip stage 2: Speed perturbation
2020-11-27T20:29:18 (asr.sh:429:main) [Require Kaldi] Stage 3: fbank_pitch extract: data/ -> dump/fbank_pitch
fix_data_dir.sh: kept all 333 utterances.
utils/copy_data_dir.sh: copied data from data/train_si84 to dump/fbank_pitch/org/train_si84
fix_data_dir.sh: old files are kept in dump/fbank_pitch/test_eval92/.backup
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
2020-11-27T20:29:22 (asr.sh:490:main) Stage 4: Remove long/short data: dump/fbank_pitch/org -> dump/fbank_pitch
utils/copy_data_dir.sh: copied data from dump/fbank_pitch/org/train_si84 to dump/fbank_pitch/train_si84
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/train_si84
fix_data_dir.sh: kept 7137 utterances out of 7138
fix_data_dir.sh: old files are kept in dump/fbank_pitch/train_si84/.backup
utils/copy_data_dir.sh: copied data from dump/fbank_pitch/org/test_dev93 to dump/fbank_pitch/test_dev93
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/test_dev93
fix_data_dir.sh: kept all 503 utterances.
fix_data_dir.sh: old files are kept in dump/fbank_pitch/test_dev93/.backup
2020-11-27T20:30:12 (asr.sh:214:main) ./asr.sh --lang en --use_lm false --token_type char --nbpe 80 --nlsyms_txt data/nlsyms.txt --lm_config conf/train_lm_transformer.yaml --asr_config conf/train_asr_transformer.yaml --inference_config conf/decode.yaml --train_set train_si84 --valid_set test_dev93 --test_sets test_dev93 test_eval92 --bpe_train_text data/train_si284/text --lm_train_text data/train_si284/text data/local/other_text/text --ngpu 1 --feats_type fbank_pitch
2020-11-27T20:30:12 (asr.sh:364:main) Stage 1: Data preparation for data/train_si84, data/test_dev93, etc.
2020-11-27T20:30:12 (data.sh:37:main) local/wsj_data_prep.sh /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_1/??-{?,??}.? /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/??-{?,??}.?
2020-11-27T20:30:34 (asr.sh:585:main) Stage 5: Generate character level token_list from data/train_si284/text data/local/other_text/text
Data preparation succeeded
2020-11-27T20:30:41 (data.sh:39:main) local/wsj_format_data.sh
local/wsj_format_data.sh 
Preparing train and test data
Succeeded in formatting data.
2020-11-27T20:30:43 (data.sh:43:main) Prepare text from lng_modl dir: /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/13-32.1/wsj1/doc/lng_modl/lm_train/np_data/{87,88,89}/*.z -> data/local/other_text/text
2020-11-27T20:31:09 (data.sh:53:main) Create non linguistic symbols: data/nlsyms.txt
<*IN*>
<*MR.*>
<NOISE>
2020-11-27T20:31:09 (asr.sh:383:main) Skip stage 2: Speed perturbation
2020-11-27T20:31:09 (asr.sh:429:main) [Require Kaldi] Stage 3: fbank_pitch extract: data/ -> dump/fbank_pitch
utils/copy_data_dir.sh: copied data from data/train_si84 to dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
2020-11-27T20:32:01 (asr.sh:214:main) ./asr.sh --lang en --use_lm false --token_type char --nbpe 80 --nlsyms_txt data/nlsyms.txt --lm_config conf/train_lm_transformer.yaml --asr_config conf/train_asr_transformer.yaml --inference_config conf/decode.yaml --train_set train_si84 --valid_set test_dev93 --test_sets test_dev93 test_eval92 --bpe_train_text data/train_si284/text --lm_train_text data/train_si284/text data/local/other_text/text --ngpu 1 --feats_type fbank_pitch
2020-11-27T20:32:02 (asr.sh:364:main) Stage 1: Data preparation for data/train_si84, data/test_dev93, etc.
2020-11-27T20:32:02 (data.sh:37:main) local/wsj_data_prep.sh /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_1/??-{?,??}.? /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/??-{?,??}.?
Data preparation succeeded
2020-11-27T20:32:19 (data.sh:39:main) local/wsj_format_data.sh
local/wsj_format_data.sh 
Preparing train and test data
Succeeded in formatting data.
2020-11-27T20:32:21 (data.sh:43:main) Prepare text from lng_modl dir: /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/13-32.1/wsj1/doc/lng_modl/lm_train/np_data/{87,88,89}/*.z -> data/local/other_text/text
2020-11-27T20:32:47 (data.sh:53:main) Create non linguistic symbols: data/nlsyms.txt
<*IN*>
<*MR.*>
<NOISE>
2020-11-27T20:32:48 (asr.sh:383:main) Skip stage 2: Speed perturbation
2020-11-27T20:32:48 (asr.sh:429:main) [Require Kaldi] Stage 3: fbank_pitch extract: data/ -> dump/fbank_pitch
utils/copy_data_dir.sh: copied data from data/train_si84 to dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
2020-11-27T20:33:34 (asr.sh:214:main) ./asr.sh --lang en --use_lm false --token_type char --nbpe 80 --nlsyms_txt data/nlsyms.txt --lm_config conf/train_lm_transformer.yaml --asr_config conf/train_asr_transformer.yaml --inference_config conf/decode.yaml --train_set train_si84 --valid_set test_dev93 --test_sets test_dev93 test_eval92 --bpe_train_text data/train_si284/text --lm_train_text data/train_si284/text data/local/other_text/text --ngpu 1 --feats_type fbank_pitch
2020-11-27T20:33:34 (asr.sh:364:main) Stage 1: Data preparation for data/train_si84, data/test_dev93, etc.
2020-11-27T20:33:34 (data.sh:37:main) local/wsj_data_prep.sh /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_1/??-{?,??}.? /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/??-{?,??}.?
Data preparation succeeded
2020-11-27T20:34:01 (data.sh:39:main) local/wsj_format_data.sh
local/wsj_format_data.sh 
Preparing train and test data
Succeeded in formatting data.
2020-11-27T20:34:03 (data.sh:43:main) Prepare text from lng_modl dir: /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/13-32.1/wsj1/doc/lng_modl/lm_train/np_data/{87,88,89}/*.z -> data/local/other_text/text
2020-11-27T20:34:11 (asr.sh:806:main) Stage 6-8: Skip lm-related stages: use_lm=false
2020-11-27T20:34:11 (asr.sh:813:main) Stage 9: ASR collect stats: train_set=dump/fbank_pitch/train_si84, valid_set=dump/fbank_pitch/test_dev93
2020-11-27T20:34:13 (asr.sh:863:main) Generate 'exp/asr_stats_fbank_pitch_char/run.sh'. You can resume the process from stage 9 using this script
2020-11-27T20:34:13 (asr.sh:867:main) ASR collect-stats started... log: 'exp/asr_stats_fbank_pitch_char/logdir/stats.*.log'
2020-11-27T20:34:31 (asr.sh:914:main) Stage 10: ASR Training: train_set=dump/fbank_pitch/train_si84, valid_set=dump/fbank_pitch/test_dev93
2020-11-27T20:34:31 (asr.sh:981:main) Generate 'exp/asr_train_asr_transformer_fbank_pitch_char/run.sh'. You can resume the process from stage 10 using this script
2020-11-27T20:34:31 (asr.sh:985:main) ASR training started... log: 'exp/asr_train_asr_transformer_fbank_pitch_char/train.log'
2020-11-27T20:34:33 (data.sh:53:main) Create non linguistic symbols: data/nlsyms.txt
<*IN*>
<*MR.*>
<NOISE>
2020-11-27T20:34:33 (asr.sh:383:main) Skip stage 2: Speed perturbation
2020-11-27T20:34:33 (asr.sh:429:main) [Require Kaldi] Stage 3: fbank_pitch extract: data/ -> dump/fbank_pitch
utils/copy_data_dir.sh: copied data from data/train_si84 to dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.

Failed a run
RUNNING:


run.pl: 32 / 32 failed, log is in dump/fbank_pitch/org/train_si84/log/make_fbank_pitch_train_si84.*.log

Failed a run
RUNNING:-dup


run.pl: 32 / 32 failed, log is in dump/fbank_pitch/org/train_si84/log/make_fbank_pitch_train_si84.*.log

Failed a run
RUNNING:-dup


run.pl: 32 / 32 failed, log is in dump/fbank_pitch/org/train_si84/log/make_fbank_pitch_train_si84.*.log

Failed a run
RUNNING:-dup


run.pl: 32 / 32 failed, log is in dump/fbank_pitch/org/train_si84/log/make_fbank_pitch_train_si84.*.log

Failed a run
RUNNING:-dup


scripts/feats/feat_to_shape.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/train_si84/feats.scp dump/fbank_pitch/org/train_si84/feats_shape
scripts/feats/feat_to_shape.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/test_dev93/feats.scp dump/fbank_pitch/org/test_dev93/feats_shape
scripts/feats/feat_to_shape.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/test_dev93/feats.scp dump/fbank_pitch/org/test_dev93/feats_shape
scripts/feats/feat_to_shape.sh --nj 32 --cmd run.pl dump/fbank_pitch/test_eval92/feats.scp dump/fbank_pitch/test_eval92/feats_shape
/afs/cs.pitt.edu/usr0/ras306/miniconda3/envs/psinet/bin/python3 /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/bin/tokenize_text.py --token_type char --input dump/fbank_pitch/lm_train.txt --output data/token_list/char/tokens.txt --non_linguistic_symbols data/nlsyms.txt --field 2- --cleaner none --g2p none --write_vocabulary true --add_symbol '<blank>:0' --add_symbol '<unk>:1' --add_symbol '<sos/eos>:-1'
2020-11-27 20:34:11,819 (tokenize_text:171) INFO: OOV rate = 0.0 %
/afs/cs.pitt.edu/usr0/ras306/miniconda3/envs/psinet/bin/python3 /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/bin/aggregate_stats_dirs.py --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.1 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.2 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.3 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.4 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.5 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.6 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.7 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.8 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.9 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.10 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.11 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.12 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.13 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.14 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.15 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.16 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.17 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.18 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.19 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.20 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.21 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.22 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.23 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.24 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.25 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.26 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.27 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.28 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.29 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.30 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.31 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.32 --output_dir exp/asr_stats_fbank_pitch_char
2020-11-27 20:34:31,739 (launch:95) INFO: /afs/cs.pitt.edu/usr0/ras306/miniconda3/envs/psinet/bin/python3 /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/bin/launch.py --cmd 'run.pl --name exp/asr_train_asr_transformer_fbank_pitch_char/train.log' --log exp/asr_train_asr_transformer_fbank_pitch_char/train.log --ngpu 1 --num_nodes 1 --init_file_prefix exp/asr_train_asr_transformer_fbank_pitch_char/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel none --token_type char --token_list data/token_list/char/tokens.txt --non_linguistic_symbols data/nlsyms.txt --cleaner none --g2p none --valid_data_path_and_name_and_type dump/fbank_pitch/test_dev93/feats.scp,speech,kaldi_ark --valid_data_path_and_name_and_type dump/fbank_pitch/test_dev93/text,text,text --valid_shape_file exp/asr_stats_fbank_pitch_char/valid/speech_shape --valid_shape_file exp/asr_stats_fbank_pitch_char/valid/text_shape.char --resume true --fold_length 800 --fold_length 150 --output_dir exp/asr_train_asr_transformer_fbank_pitch_char --config conf/train_asr_transformer.yaml --input_size=123 --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_fbank_pitch_char/train/feats_stats.npz --train_data_path_and_name_and_type dump/fbank_pitch/train_si84/feats.scp,speech,kaldi_ark --train_data_path_and_name_and_type dump/fbank_pitch/train_si84/text,text,text --train_shape_file exp/asr_stats_fbank_pitch_char/train/speech_shape --train_shape_file exp/asr_stats_fbank_pitch_char/train/text_shape.char
2020-11-27 20:34:31,870 (launch:349) INFO: log file: exp/asr_train_asr_transformer_fbank_pitch_char/train.log
run.pl: job failed, log is in exp/asr_train_asr_transformer_fbank_pitch_char/train.log
Command '['run.pl', '--name', 'exp/asr_train_asr_transformer_fbank_pitch_char/train.log', '--gpu', '1', 'exp/asr_train_asr_transformer_fbank_pitch_char/train.log', 'python3', '-m', 'espnet2.bin.asr_train', '--use_preprocessor', 'true', '--bpemodel', 'none', '--token_type', 'char', '--token_list', 'data/token_list/char/tokens.txt', '--non_linguistic_symbols', 'data/nlsyms.txt', '--cleaner', 'none', '--g2p', 'none', '--valid_data_path_and_name_and_type', 'dump/fbank_pitch/test_dev93/feats.scp,speech,kaldi_ark', '--valid_data_path_and_name_and_type', 'dump/fbank_pitch/test_dev93/text,text,text', '--valid_shape_file', 'exp/asr_stats_fbank_pitch_char/valid/speech_shape', '--valid_shape_file', 'exp/asr_stats_fbank_pitch_char/valid/text_shape.char', '--resume', 'true', '--fold_length', '800', '--fold_length', '150', '--output_dir', 'exp/asr_train_asr_transformer_fbank_pitch_char', '--config', 'conf/train_asr_transformer.yaml', '--input_size=123', '--normalize=global_mvn', '--normalize_conf', 'stats_file=exp/asr_stats_fbank_pitch_char/train/feats_stats.npz', '--train_data_path_and_name_and_type', 'dump/fbank_pitch/train_si84/feats.scp,speech,kaldi_ark', '--train_data_path_and_name_and_type', 'dump/fbank_pitch/train_si84/text,text,text', '--train_shape_file', 'exp/asr_stats_fbank_pitch_char/train/speech_shape', '--train_shape_file', 'exp/asr_stats_fbank_pitch_char/train/text_shape.char', '--ngpu', '1', '--multiprocessing_distributed', 'True']' returned non-zero exit status 1.
Traceback (most recent call last):
  File "/afs/cs.pitt.edu/usr0/ras306/miniconda3/envs/psinet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/afs/cs.pitt.edu/usr0/ras306/miniconda3/envs/psinet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/bin/launch.py", line 385, in <module>
    main()
  File "/afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/bin/launch.py", line 378, in main
    f"###################\n" + "".join(lines[-1000:])
RuntimeError: 
################### The last 1000 lines of exp/asr_train_asr_transformer_fbank_pitch_char/train.log ###################
# python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel none --token_type char --token_list data/token_list/char/tokens.txt --non_linguistic_symbols data/nlsyms.txt --cleaner none --g2p none --valid_data_path_and_name_and_type dump/fbank_pitch/test_dev93/feats.scp,speech,kaldi_ark --valid_data_path_and_name_and_type dump/fbank_pitch/test_dev93/text,text,text --valid_shape_file exp/asr_stats_fbank_pitch_char/valid/speech_shape --valid_shape_file exp/asr_stats_fbank_pitch_char/valid/text_shape.char --resume true --fold_length 800 --fold_length 150 --output_dir exp/asr_train_asr_transformer_fbank_pitch_char --config conf/train_asr_transformer.yaml --input_size=123 --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_fbank_pitch_char/train/feats_stats.npz --train_data_path_and_name_and_type dump/fbank_pitch/train_si84/feats.scp,speech,kaldi_ark --train_data_path_and_name_and_type dump/fbank_pitch/train_si84/text,text,text --train_shape_file exp/asr_stats_fbank_pitch_char/train/speech_shape --train_shape_file exp/asr_stats_fbank_pitch_char/train/text_shape.char --ngpu 1 --multiprocessing_distributed True 
# Started at Fri Nov 27 20:34:31 EST 2020
#
/afs/cs.pitt.edu/usr0/ras306/miniconda3/envs/psinet/bin/python3 /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/bin/asr_train.py --use_preprocessor true --bpemodel none --token_type char --token_list data/token_list/char/tokens.txt --non_linguistic_symbols data/nlsyms.txt --cleaner none --g2p none --valid_data_path_and_name_and_type dump/fbank_pitch/test_dev93/feats.scp,speech,kaldi_ark --valid_data_path_and_name_and_type dump/fbank_pitch/test_dev93/text,text,text --valid_shape_file exp/asr_stats_fbank_pitch_char/valid/speech_shape --valid_shape_file exp/asr_stats_fbank_pitch_char/valid/text_shape.char --resume true --fold_length 800 --fold_length 150 --output_dir exp/asr_train_asr_transformer_fbank_pitch_char --config conf/train_asr_transformer.yaml --input_size=123 --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_fbank_pitch_char/train/feats_stats.npz --train_data_path_and_name_and_type dump/fbank_pitch/train_si84/feats.scp,speech,kaldi_ark --train_data_path_and_name_and_type dump/fbank_pitch/train_si84/text,text,text --train_shape_file exp/asr_stats_fbank_pitch_char/train/speech_shape --train_shape_file exp/asr_stats_fbank_pitch_char/train/text_shape.char --ngpu 1 --multiprocessing_distributed True
[magnolia] 2020-11-27 20:34:34,833 (asr:283) INFO: Vocabulary size: 65
[magnolia] 2020-11-27 20:34:38,714 (abs_task:1068) INFO: pytorch.version=1.4.0, cuda.available=True, cudnn.version=7603, cudnn.benchmark=False, cudnn.deterministic=True
[magnolia] 2020-11-27 20:34:38,719 (abs_task:1069) INFO: Model structure:
ESPnetASRModel(
  (normalize): GlobalMVN(stats_file=exp/asr_stats_fbank_pitch_char/train/feats_stats.npz, norm_means=True, norm_vars=True)
  (encoder): TransformerEncoder(
    (embed): Conv2dSubsampling(
      (conv): Sequential(
        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=7680, out_features=256, bias=True)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (encoders): MultiSequential(
      (0): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (2): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (3): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (4): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (5): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (6): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (7): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (8): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (9): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (10): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (11): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (embed): Sequential(
      (0): Embedding(65, 256)
      (1): PositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
    (output_layer): Linear(in_features=256, out_features=65, bias=True)
    (decoders): MultiSequential(
      (0): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (2): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (3): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (4): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (5): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=256, out_features=65, bias=True)
    (ctc_loss): CTCLoss()
  )
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
)

Model summary:
    Class Name: ESPnetASRModel
    Number of parameters: 27.86 M
    Size: 111.45 MB
    Type: torch.float32
[magnolia] 2020-11-27 20:34:38,720 (abs_task:1072) INFO: Optimizer:
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.005
    lr: 1.6666666666666665e-07
    weight_decay: 0
)
[magnolia] 2020-11-27 20:34:38,720 (abs_task:1073) INFO: Scheduler: WarmupLR(warmup_steps=30000)
[magnolia] 2020-11-27 20:34:38,724 (abs_task:1083) INFO: Saving the configuration in exp/asr_train_asr_transformer_fbank_pitch_char/config.yaml
Traceback (most recent call last):
  File "/afs/cs.pitt.edu/usr0/ras306/miniconda3/envs/psinet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/afs/cs.pitt.edu/usr0/ras306/miniconda3/envs/psinet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/bin/asr_train.py", line 23, in <module>
    main()
  File "/afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/bin/asr_train.py", line 19, in main
    ASRTask.main(cmd=cmd)
  File "/afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/tasks/abs_task.py", line 941, in main
    cls.main_worker(args)
  File "/afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/tasks/abs_task.py", line 1122, in main_worker
    ngpu=args.ngpu,
  File "/afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/tasks/abs_task.py", line 899, in resume
    model.load_state_dict(states["model"])
  File "/afs/cs.pitt.edu/usr0/ras306/miniconda3/envs/psinet/lib/python3.7/site-packages/torch/nn/modules/module.py", line 830, in load_state_dict
    self.__class__.__name__, "\n\t".join(error_msgs)))
RuntimeError: Error(s) in loading state_dict for ESPnetASRModel:
	size mismatch for normalize.mean: copying a param with shape torch.Size([26]) from checkpoint, the shape in current model is torch.Size([123]).
	size mismatch for normalize.std: copying a param with shape torch.Size([26]) from checkpoint, the shape in current model is torch.Size([123]).
	size mismatch for encoder.embed.out.0.weight: copying a param with shape torch.Size([256, 1280]) from checkpoint, the shape in current model is torch.Size([256, 7680]).
# Accounting: time=8 threads=1
# Ended (code 1) at Fri Nov 27 20:34:39 EST 2020, elapsed time 8 seconds

2020-11-27T20:34:40 (asr.sh:214:main) ./asr.sh --lang en --use_lm false --token_type char --nbpe 80 --nlsyms_txt data/nlsyms.txt --lm_config conf/train_lm_transformer.yaml --asr_config conf/train_asr_transformer.yaml --inference_config conf/decode.yaml --train_set train_si84 --valid_set test_dev93 --test_sets test_dev93 test_eval92 --bpe_train_text data/train_si284/text --lm_train_text data/train_si284/text data/local/other_text/text --ngpu 1 --feats_type fbank_pitch
2020-11-27T20:34:42 (asr.sh:364:main) Stage 1: Data preparation for data/train_si84, data/test_dev93, etc.
2020-11-27T20:34:43 (data.sh:37:main) local/wsj_data_prep.sh /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_1/??-{?,??}.? /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/??-{?,??}.?
2020-11-27T20:35:18 (asr.sh:214:main) ./asr.sh --lang en --use_lm false --token_type char --nbpe 80 --nlsyms_txt data/nlsyms.txt --lm_config conf/train_lm_transformer.yaml --asr_config conf/train_asr_transformer.yaml --inference_config conf/decode.yaml --train_set train_si84 --valid_set test_dev93 --test_sets test_dev93 test_eval92 --bpe_train_text data/train_si284/text --lm_train_text data/train_si284/text data/local/other_text/text --ngpu 1 --feats_type fbank_pitch
2020-11-27T20:35:19 (asr.sh:364:main) Stage 1: Data preparation for data/train_si84, data/test_dev93, etc.
2020-11-27T20:35:19 (data.sh:37:main) local/wsj_data_prep.sh /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_1/??-{?,??}.? /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/??-{?,??}.?
Data preparation succeeded
2020-11-27T20:35:43 (data.sh:39:main) local/wsj_format_data.sh
local/wsj_format_data.sh 
Data preparation succeeded
2020-11-27T20:35:43 (data.sh:39:main) local/wsj_format_data.sh
local/wsj_format_data.sh 
Preparing train and test data
Preparing train and test data
Succeeded in formatting data.
2020-11-27T20:35:46 (data.sh:43:main) Prepare text from lng_modl dir: /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/13-32.1/wsj1/doc/lng_modl/lm_train/np_data/{87,88,89}/*.z -> data/local/other_text/text
Succeeded in formatting data.
2020-11-27T20:35:46 (data.sh:43:main) Prepare text from lng_modl dir: /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/13-32.1/wsj1/doc/lng_modl/lm_train/np_data/{87,88,89}/*.z -> data/local/other_text/text
2020-11-27T20:36:31 (data.sh:53:main) Create non linguistic symbols: data/nlsyms.txt
2020-11-27T20:36:31 (data.sh:53:main) Create non linguistic symbols: data/nlsyms.txt
<*IN*>
<*MR.*>
<NOISE>
2020-11-27T20:36:31 (asr.sh:383:main) Skip stage 2: Speed perturbation
2020-11-27T20:36:31 (asr.sh:429:main) [Require Kaldi] Stage 3: fbank_pitch extract: data/ -> dump/fbank_pitch
<*IN*>
<*MR.*>
<NOISE>
2020-11-27T20:36:31 (asr.sh:383:main) Skip stage 2: Speed perturbation
2020-11-27T20:36:31 (asr.sh:429:main) [Require Kaldi] Stage 3: fbank_pitch extract: data/ -> dump/fbank_pitch
utils/copy_data_dir.sh: copied data from data/train_si84 to dump/fbank_pitch/org/train_si84
utils/copy_data_dir.sh: file feats.scp exists in dest dump/fbank_pitch/org/train_si84 but not in src data/train_si84.  Moving it to
 ... dump/fbank_pitch/org/train_si84/.backup/feats.scp
utils/copy_data_dir.sh: file utt2dur exists in dest dump/fbank_pitch/org/train_si84 but not in src data/train_si84.  Moving it to
 ... dump/fbank_pitch/org/train_si84/.backup/utt2dur
utils/copy_data_dir.sh: file utt2num_frames exists in dest dump/fbank_pitch/org/train_si84 but not in src data/train_si84.  Moving it to
 ... dump/fbank_pitch/org/train_si84/.backup/utt2num_frames
utils/copy_data_dir.sh: file frame_shift exists in dest dump/fbank_pitch/org/train_si84 but not in src data/train_si84.  Moving it to
 ... dump/fbank_pitch/org/train_si84/.backup/frame_shift
utils/copy_data_dir.sh: copied data from data/train_si84 to dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
2020-11-27T20:38:28 (asr.sh:214:main) ./asr.sh --lang en --use_lm false --token_type char --nbpe 80 --nlsyms_txt data/nlsyms.txt --lm_config conf/train_lm_transformer.yaml --asr_config conf/train_asr_transformer.yaml --inference_config conf/decode.yaml --train_set train_si84 --valid_set test_dev93 --test_sets test_dev93 test_eval92 --bpe_train_text data/train_si284/text --lm_train_text data/train_si284/text data/local/other_text/text --ngpu 1 --feats_type fbank_pitch
2020-11-27T20:38:28 (asr.sh:214:main) ./asr.sh --lang en --use_lm false --token_type char --nbpe 80 --nlsyms_txt data/nlsyms.txt --lm_config conf/train_lm_transformer.yaml --asr_config conf/train_asr_transformer.yaml --inference_config conf/decode.yaml --train_set train_si84 --valid_set test_dev93 --test_sets test_dev93 test_eval92 --bpe_train_text data/train_si284/text --lm_train_text data/train_si284/text data/local/other_text/text --ngpu 1 --feats_type fbank_pitch
2020-11-27T20:38:29 (asr.sh:364:main) Stage 1: Data preparation for data/train_si84, data/test_dev93, etc.
2020-11-27T20:38:29 (asr.sh:364:main) Stage 1: Data preparation for data/train_si84, data/test_dev93, etc.
2020-11-27T20:38:29 (data.sh:37:main) local/wsj_data_prep.sh /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_1/??-{?,??}.? /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/??-{?,??}.?
2020-11-27T20:38:29 (data.sh:37:main) local/wsj_data_prep.sh /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_1/??-{?,??}.? /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/??-{?,??}.?
Data preparation succeeded
Data preparation succeeded
2020-11-27T20:38:57 (data.sh:39:main) local/wsj_format_data.sh
2020-11-27T20:38:57 (data.sh:39:main) local/wsj_format_data.sh
local/wsj_format_data.sh 
local/wsj_format_data.sh 
Preparing train and test data
Preparing train and test data
Succeeded in formatting data.
2020-11-27T20:39:00 (data.sh:43:main) Prepare text from lng_modl dir: /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/13-32.1/wsj1/doc/lng_modl/lm_train/np_data/{87,88,89}/*.z -> data/local/other_text/text
Succeeded in formatting data.
2020-11-27T20:39:00 (data.sh:43:main) Prepare text from lng_modl dir: /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/13-32.1/wsj1/doc/lng_modl/lm_train/np_data/{87,88,89}/*.z -> data/local/other_text/text
2020-11-27T20:39:44 (data.sh:53:main) Create non linguistic symbols: data/nlsyms.txt
2020-11-27T20:39:44 (data.sh:53:main) Create non linguistic symbols: data/nlsyms.txt
<*IN*>
<*MR.*>
<NOISE>
2020-11-27T20:39:44 (asr.sh:383:main) Skip stage 2: Speed perturbation
2020-11-27T20:39:44 (asr.sh:429:main) [Require Kaldi] Stage 3: fbank_pitch extract: data/ -> dump/fbank_pitch
<*IN*>
<*MR.*>
<NOISE>
2020-11-27T20:39:44 (asr.sh:383:main) Skip stage 2: Speed perturbation
2020-11-27T20:39:44 (asr.sh:429:main) [Require Kaldi] Stage 3: fbank_pitch extract: data/ -> dump/fbank_pitch
utils/copy_data_dir.sh: copied data from data/train_si84 to dump/fbank_pitch/org/train_si84
utils/copy_data_dir.sh: copied data from data/train_si84 to dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
2020-11-27T20:41:34 (asr.sh:214:main) ./asr.sh --lang en --use_lm false --token_type char --nbpe 80 --nlsyms_txt data/nlsyms.txt --lm_config conf/train_lm_transformer.yaml --asr_config conf/train_asr_transformer.yaml --inference_config conf/decode.yaml --train_set train_si84 --valid_set test_dev93 --test_sets test_dev93 test_eval92 --bpe_train_text data/train_si284/text --lm_train_text data/train_si284/text data/local/other_text/text --ngpu 1 --feats_type fbank_pitch
2020-11-27T20:41:37 (asr.sh:364:main) Stage 1: Data preparation for data/train_si84, data/test_dev93, etc.
2020-11-27T20:41:37 (data.sh:37:main) local/wsj_data_prep.sh /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_1/??-{?,??}.? /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/??-{?,??}.?
2020-11-27T20:41:38 (asr.sh:214:main) ./asr.sh --lang en --use_lm false --token_type char --nbpe 80 --nlsyms_txt data/nlsyms.txt --lm_config conf/train_lm_transformer.yaml --asr_config conf/train_asr_transformer.yaml --inference_config conf/decode.yaml --train_set train_si84 --valid_set test_dev93 --test_sets test_dev93 test_eval92 --bpe_train_text data/train_si284/text --lm_train_text data/train_si284/text data/local/other_text/text --ngpu 1 --feats_type fbank_pitch
2020-11-27T20:41:39 (asr.sh:364:main) Stage 1: Data preparation for data/train_si84, data/test_dev93, etc.
2020-11-27T20:41:39 (data.sh:37:main) local/wsj_data_prep.sh /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_1/??-{?,??}.? /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/??-{?,??}.?
Data preparation succeeded
2020-11-27T20:42:00 (data.sh:39:main) local/wsj_format_data.sh
local/wsj_format_data.sh 
Data preparation succeeded
2020-11-27T20:42:00 (data.sh:39:main) local/wsj_format_data.sh
local/wsj_format_data.sh 
Preparing train and test data
Preparing train and test data
Succeeded in formatting data.
2020-11-27T20:42:03 (data.sh:43:main) Prepare text from lng_modl dir: /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/13-32.1/wsj1/doc/lng_modl/lm_train/np_data/{87,88,89}/*.z -> data/local/other_text/text
Succeeded in formatting data.
2020-11-27T20:42:03 (data.sh:43:main) Prepare text from lng_modl dir: /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/13-32.1/wsj1/doc/lng_modl/lm_train/np_data/{87,88,89}/*.z -> data/local/other_text/text
2020-11-27T20:42:46 (data.sh:53:main) Create non linguistic symbols: data/nlsyms.txt
2020-11-27T20:42:46 (data.sh:53:main) Create non linguistic symbols: data/nlsyms.txt
<*IN*>
<*MR.*>
<NOISE>
2020-11-27T20:42:46 (asr.sh:383:main) Skip stage 2: Speed perturbation
2020-11-27T20:42:46 (asr.sh:429:main) [Require Kaldi] Stage 3: fbank_pitch extract: data/ -> dump/fbank_pitch
<*IN*>
<*MR.*>
<NOISE>
2020-11-27T20:42:46 (asr.sh:383:main) Skip stage 2: Speed perturbation
2020-11-27T20:42:46 (asr.sh:429:main) [Require Kaldi] Stage 3: fbank_pitch extract: data/ -> dump/fbank_pitch
utils/copy_data_dir.sh: copied data from data/train_si84 to dump/fbank_pitch/org/train_si84
utils/copy_data_dir.sh: copied data from data/train_si84 to dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
2020-11-27T20:44:49 (asr.sh:214:main) ./asr.sh --lang en --use_lm false --token_type char --nbpe 80 --nlsyms_txt data/nlsyms.txt --lm_config conf/train_lm_transformer.yaml --asr_config conf/train_asr_transformer.yaml --inference_config conf/decode.yaml --train_set train_si84 --valid_set test_dev93 --test_sets test_dev93 test_eval92 --bpe_train_text data/train_si284/text --lm_train_text data/train_si284/text data/local/other_text/text --ngpu 1 --feats_type fbank_pitch
steps/make_fbank_pitch.sh: Succeeded creating filterbank and pitch features for train_si84
2020-11-27T20:44:50 (asr.sh:364:main) Stage 1: Data preparation for data/train_si84, data/test_dev93, etc.
2020-11-27T20:44:50 (data.sh:37:main) local/wsj_data_prep.sh /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_1/??-{?,??}.? /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/??-{?,??}.?
fix_data_dir.sh: kept all 7138 utterances.
fix_data_dir.sh: old files are kept in dump/fbank_pitch/org/train_si84/.backup
utils/copy_data_dir.sh: copied data from data/test_dev93 to dump/fbank_pitch/org/test_dev93
utils/copy_data_dir.sh: file feats.scp exists in dest dump/fbank_pitch/org/test_dev93 but not in src data/test_dev93.  Moving it to
 ... dump/fbank_pitch/org/test_dev93/.backup/feats.scp
utils/copy_data_dir.sh: file utt2dur exists in dest dump/fbank_pitch/org/test_dev93 but not in src data/test_dev93.  Moving it to
 ... dump/fbank_pitch/org/test_dev93/.backup/utt2dur
utils/copy_data_dir.sh: file utt2num_frames exists in dest dump/fbank_pitch/org/test_dev93 but not in src data/test_dev93.  Moving it to
 ... dump/fbank_pitch/org/test_dev93/.backup/utt2num_frames
utils/copy_data_dir.sh: file frame_shift exists in dest dump/fbank_pitch/org/test_dev93 but not in src data/test_dev93.  Moving it to
 ... dump/fbank_pitch/org/test_dev93/.backup/frame_shift
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/test_dev93
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/test_dev93
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/test_dev93
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_fbank_pitch.sh: Succeeded creating filterbank and pitch features for test_dev93
fix_data_dir.sh: kept all 503 utterances.
fix_data_dir.sh: old files are kept in dump/fbank_pitch/org/test_dev93/.backup
utils/copy_data_dir.sh: copied data from data/test_dev93 to dump/fbank_pitch/org/test_dev93
utils/copy_data_dir.sh: file feats.scp exists in dest dump/fbank_pitch/org/test_dev93 but not in src data/test_dev93.  Moving it to
 ... dump/fbank_pitch/org/test_dev93/.backup/feats.scp
utils/copy_data_dir.sh: file utt2dur exists in dest dump/fbank_pitch/org/test_dev93 but not in src data/test_dev93.  Moving it to
 ... dump/fbank_pitch/org/test_dev93/.backup/utt2dur
utils/copy_data_dir.sh: file utt2num_frames exists in dest dump/fbank_pitch/org/test_dev93 but not in src data/test_dev93.  Moving it to
 ... dump/fbank_pitch/org/test_dev93/.backup/utt2num_frames
utils/copy_data_dir.sh: file frame_shift exists in dest dump/fbank_pitch/org/test_dev93 but not in src data/test_dev93.  Moving it to
 ... dump/fbank_pitch/org/test_dev93/.backup/frame_shift
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/test_dev93
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/test_dev93
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/test_dev93
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_fbank_pitch.sh: Succeeded creating filterbank and pitch features for test_dev93
fix_data_dir.sh: kept all 503 utterances.
fix_data_dir.sh: old files are kept in dump/fbank_pitch/org/test_dev93/.backup
utils/copy_data_dir.sh: copied data from data/test_eval92 to dump/fbank_pitch/test_eval92
utils/copy_data_dir.sh: file feats.scp exists in dest dump/fbank_pitch/test_eval92 but not in src data/test_eval92.  Moving it to
 ... dump/fbank_pitch/test_eval92/.backup/feats.scp
utils/copy_data_dir.sh: file utt2dur exists in dest dump/fbank_pitch/test_eval92 but not in src data/test_eval92.  Moving it to
 ... dump/fbank_pitch/test_eval92/.backup/utt2dur
utils/copy_data_dir.sh: file utt2num_frames exists in dest dump/fbank_pitch/test_eval92 but not in src data/test_eval92.  Moving it to
 ... dump/fbank_pitch/test_eval92/.backup/utt2num_frames
utils/copy_data_dir.sh: file frame_shift exists in dest dump/fbank_pitch/test_eval92 but not in src data/test_eval92.  Moving it to
 ... dump/fbank_pitch/test_eval92/.backup/frame_shift
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/test_eval92
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/test_eval92
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/test_eval92
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_fbank_pitch.sh: Succeeded creating filterbank and pitch features for test_eval92
Data preparation succeeded
2020-11-27T20:45:33 (data.sh:39:main) local/wsj_format_data.sh
local/wsj_format_data.sh 
fix_data_dir.sh: kept all 333 utterances.
Preparing train and test data
fix_data_dir.sh: old files are kept in dump/fbank_pitch/test_eval92/.backup
Succeeded in formatting data.
2020-11-27T20:45:37 (data.sh:43:main) Prepare text from lng_modl dir: /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/13-32.1/wsj1/doc/lng_modl/lm_train/np_data/{87,88,89}/*.z -> data/local/other_text/text
2020-11-27T20:45:38 (asr.sh:490:main) Stage 4: Remove long/short data: dump/fbank_pitch/org -> dump/fbank_pitch
utils/copy_data_dir.sh: copied data from dump/fbank_pitch/org/train_si84 to dump/fbank_pitch/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/train_si84
fix_data_dir.sh: kept 7137 utterances out of 7138
fix_data_dir.sh: old files are kept in dump/fbank_pitch/train_si84/.backup
utils/copy_data_dir.sh: copied data from dump/fbank_pitch/org/test_dev93 to dump/fbank_pitch/test_dev93
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/test_dev93
fix_data_dir.sh: kept all 503 utterances.
fix_data_dir.sh: old files are kept in dump/fbank_pitch/test_dev93/.backup
2020-11-27T20:46:17 (data.sh:53:main) Create non linguistic symbols: data/nlsyms.txt
<*IN*>
<*MR.*>
<NOISE>
2020-11-27T20:46:17 (asr.sh:383:main) Skip stage 2: Speed perturbation
2020-11-27T20:46:17 (asr.sh:429:main) [Require Kaldi] Stage 3: fbank_pitch extract: data/ -> dump/fbank_pitch
utils/copy_data_dir.sh: copied data from data/train_si84 to dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
2020-11-27T20:46:26 (asr.sh:585:main) Stage 5: Generate character level token_list from data/train_si284/text data/local/other_text/text
2020-11-27T20:47:10 (asr.sh:214:main) ./asr.sh --lang en --use_lm false --token_type char --nbpe 80 --nlsyms_txt data/nlsyms.txt --lm_config conf/train_lm_transformer.yaml --asr_config conf/train_asr_transformer.yaml --inference_config conf/decode.yaml --train_set train_si84 --valid_set test_dev93 --test_sets test_dev93 test_eval92 --bpe_train_text data/train_si284/text --lm_train_text data/train_si284/text data/local/other_text/text --ngpu 1 --feats_type fbank_pitch
2020-11-27T20:47:11 (asr.sh:364:main) Stage 1: Data preparation for data/train_si84, data/test_dev93, etc.
2020-11-27T20:47:11 (data.sh:37:main) local/wsj_data_prep.sh /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_1/??-{?,??}.? /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/??-{?,??}.?
Data preparation succeeded
2020-11-27T20:47:28 (data.sh:39:main) local/wsj_format_data.sh
local/wsj_format_data.sh 
Preparing train and test data
Succeeded in formatting data.
2020-11-27T20:47:30 (data.sh:43:main) Prepare text from lng_modl dir: /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/13-32.1/wsj1/doc/lng_modl/lm_train/np_data/{87,88,89}/*.z -> data/local/other_text/text
2020-11-27T20:47:56 (data.sh:53:main) Create non linguistic symbols: data/nlsyms.txt
<*IN*>
<*MR.*>
<NOISE>
2020-11-27T20:47:56 (asr.sh:383:main) Skip stage 2: Speed perturbation
2020-11-27T20:47:56 (asr.sh:429:main) [Require Kaldi] Stage 3: fbank_pitch extract: data/ -> dump/fbank_pitch
utils/copy_data_dir.sh: copied data from data/train_si84 to dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
2020-11-27T20:48:41 (asr.sh:214:main) ./asr.sh --lang en --use_lm false --token_type char --nbpe 80 --nlsyms_txt data/nlsyms.txt --lm_config conf/train_lm_transformer.yaml --asr_config conf/train_asr_transformer.yaml --inference_config conf/decode.yaml --train_set train_si84 --valid_set test_dev93 --test_sets test_dev93 test_eval92 --bpe_train_text data/train_si284/text --lm_train_text data/train_si284/text data/local/other_text/text --ngpu 1 --feats_type fbank_pitch
2020-11-27T20:48:42 (asr.sh:364:main) Stage 1: Data preparation for data/train_si84, data/test_dev93, etc.
2020-11-27T20:48:42 (data.sh:37:main) local/wsj_data_prep.sh /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_1/??-{?,??}.? /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/??-{?,??}.?
Data preparation succeeded
2020-11-27T20:48:57 (data.sh:39:main) local/wsj_format_data.sh
local/wsj_format_data.sh 
Preparing train and test data
Succeeded in formatting data.
2020-11-27T20:48:59 (data.sh:43:main) Prepare text from lng_modl dir: /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/13-32.1/wsj1/doc/lng_modl/lm_train/np_data/{87,88,89}/*.z -> data/local/other_text/text
2020-11-27T20:49:25 (data.sh:53:main) Create non linguistic symbols: data/nlsyms.txt
<*IN*>
<*MR.*>
<NOISE>
2020-11-27T20:49:26 (asr.sh:383:main) Skip stage 2: Speed perturbation
2020-11-27T20:49:26 (asr.sh:429:main) [Require Kaldi] Stage 3: fbank_pitch extract: data/ -> dump/fbank_pitch
utils/copy_data_dir.sh: copied data from data/train_si84 to dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
2020-11-27T20:49:31 (asr.sh:214:main) ./asr.sh --lang en --use_lm false --token_type char --nbpe 80 --nlsyms_txt data/nlsyms.txt --lm_config conf/train_lm_transformer.yaml --asr_config conf/train_asr_transformer.yaml --inference_config conf/decode.yaml --train_set train_si84 --valid_set test_dev93 --test_sets test_dev93 test_eval92 --bpe_train_text data/train_si284/text --lm_train_text data/train_si284/text data/local/other_text/text --ngpu 1 --feats_type fbank_pitch
2020-11-27T20:49:31 (asr.sh:364:main) Stage 1: Data preparation for data/train_si84, data/test_dev93, etc.
2020-11-27T20:49:31 (data.sh:37:main) local/wsj_data_prep.sh /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_1/??-{?,??}.? /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/??-{?,??}.?
Data preparation succeeded
2020-11-27T20:49:46 (data.sh:39:main) local/wsj_format_data.sh
local/wsj_format_data.sh 
Preparing train and test data
Succeeded in formatting data.
2020-11-27T20:49:48 (data.sh:43:main) Prepare text from lng_modl dir: /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/13-32.1/wsj1/doc/lng_modl/lm_train/np_data/{87,88,89}/*.z -> data/local/other_text/text
2020-11-27T20:50:14 (data.sh:53:main) Create non linguistic symbols: data/nlsyms.txt
<*IN*>
<*MR.*>
<NOISE>
2020-11-27T20:50:15 (asr.sh:383:main) Skip stage 2: Speed perturbation
2020-11-27T20:50:15 (asr.sh:429:main) [Require Kaldi] Stage 3: fbank_pitch extract: data/ -> dump/fbank_pitch
utils/copy_data_dir.sh: copied data from data/train_si84 to dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
2020-11-27T20:50:26 (asr.sh:806:main) Stage 6-8: Skip lm-related stages: use_lm=false
2020-11-27T20:50:26 (asr.sh:813:main) Stage 9: ASR collect stats: train_set=dump/fbank_pitch/train_si84, valid_set=dump/fbank_pitch/test_dev93
2020-11-27T20:50:28 (asr.sh:863:main) Generate 'exp/asr_stats_fbank_pitch_char/run.sh'. You can resume the process from stage 9 using this script
2020-11-27T20:50:28 (asr.sh:867:main) ASR collect-stats started... log: 'exp/asr_stats_fbank_pitch_char/logdir/stats.*.log'
2020-11-27T20:51:24 (asr.sh:214:main) ./asr.sh --lang en --use_lm false --token_type char --nbpe 80 --nlsyms_txt data/nlsyms.txt --lm_config conf/train_lm_transformer.yaml --asr_config conf/train_asr_transformer.yaml --inference_config conf/decode.yaml --train_set train_si84 --valid_set test_dev93 --test_sets test_dev93 test_eval92 --bpe_train_text data/train_si284/text --lm_train_text data/train_si284/text data/local/other_text/text --ngpu 1 --feats_type fbank_pitch
2020-11-27T20:51:24 (asr.sh:364:main) Stage 1: Data preparation for data/train_si84, data/test_dev93, etc.
2020-11-27T20:51:24 (data.sh:37:main) local/wsj_data_prep.sh /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_1/??-{?,??}.? /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/??-{?,??}.?
2020-11-27T20:51:52 (asr.sh:914:main) Stage 10: ASR Training: train_set=dump/fbank_pitch/train_si84, valid_set=dump/fbank_pitch/test_dev93
2020-11-27T20:51:52 (asr.sh:981:main) Generate 'exp/asr_train_asr_transformer_fbank_pitch_char/run.sh'. You can resume the process from stage 10 using this script
2020-11-27T20:51:52 (asr.sh:985:main) ASR training started... log: 'exp/asr_train_asr_transformer_fbank_pitch_char/train.log'
Data preparation succeeded
2020-11-27T20:51:57 (data.sh:39:main) local/wsj_format_data.sh
local/wsj_format_data.sh 
Preparing train and test data
Succeeded in formatting data.
2020-11-27T20:51:59 (data.sh:43:main) Prepare text from lng_modl dir: /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/13-32.1/wsj1/doc/lng_modl/lm_train/np_data/{87,88,89}/*.z -> data/local/other_text/text
2020-11-27T20:52:30 (data.sh:53:main) Create non linguistic symbols: data/nlsyms.txt
<*IN*>
<*MR.*>
<NOISE>
2020-11-27T20:52:31 (asr.sh:383:main) Skip stage 2: Speed perturbation
2020-11-27T20:52:31 (asr.sh:429:main) [Require Kaldi] Stage 3: fbank_pitch extract: data/ -> dump/fbank_pitch
utils/copy_data_dir.sh: copied data from data/train_si84 to dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
2020-11-27T20:53:17 (asr.sh:214:main) ./asr.sh --lang en --use_lm false --token_type char --nbpe 80 --nlsyms_txt data/nlsyms.txt --lm_config conf/train_lm_transformer.yaml --asr_config conf/train_asr_transformer.yaml --inference_config conf/decode.yaml --train_set train_si84 --valid_set test_dev93 --test_sets test_dev93 test_eval92 --bpe_train_text data/train_si284/text --lm_train_text data/train_si284/text data/local/other_text/text --ngpu 1 --feats_type fbank_pitch
2020-11-27T20:53:18 (asr.sh:364:main) Stage 1: Data preparation for data/train_si84, data/test_dev93, etc.
2020-11-27T20:53:18 (data.sh:37:main) local/wsj_data_prep.sh /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_1/??-{?,??}.? /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/??-{?,??}.?

Failed a run
RUNNING:


run.pl: 32 / 32 failed, log is in dump/fbank_pitch/org/train_si84/log/make_fbank_pitch_train_si84.*.log

Failed a run
RUNNING:-dup


run.pl: 32 / 32 failed, log is in dump/fbank_pitch/org/train_si84/log/make_fbank_pitch_train_si84.*.log

Failed a run
RUNNING:-dup


run.pl: 32 / 32 failed, log is in dump/fbank_pitch/org/train_si84/log/make_fbank_pitch_train_si84.*.log

Failed a run
RUNNING:


run.pl: 32 / 32 failed, log is in dump/fbank_pitch/org/train_si84/log/make_fbank_pitch_train_si84.*.log

Failed a run
RUNNING:-dup


run.pl: 32 / 32 failed, log is in dump/fbank_pitch/org/train_si84/log/make_fbank_pitch_train_si84.*.log

Failed a run
RUNNING:


run.pl: 32 / 32 failed, log is in dump/fbank_pitch/org/train_si84/log/make_fbank_pitch_train_si84.*.log

Failed a run
RUNNING:-dup


run.pl: 32 / 32 failed, log is in dump/fbank_pitch/org/train_si84/log/make_fbank_pitch_train_si84.*.log

Failed a run
RUNNING:-dup


run.pl: 32 / 32 failed, log is in dump/fbank_pitch/org/train_si84/log/make_fbank_pitch_train_si84.*.log

Failed a run
RUNNING:-dup


run.pl: 32 / 32 failed, log is in dump/fbank_pitch/org/train_si84/log/make_fbank_pitch_train_si84.*.log

Failed a run
RUNNING:-dup


run.pl: 32 / 32 failed, log is in dump/fbank_pitch/org/train_si84/log/make_fbank_pitch_train_si84.*.log

Failed a run
RUNNING:-dup


run.pl: 32 / 32 failed, log is in dump/fbank_pitch/org/train_si84/log/make_fbank_pitch_train_si84.*.log

Failed a run
RUNNING:-dup


scripts/feats/feat_to_shape.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/train_si84/feats.scp dump/fbank_pitch/org/train_si84/feats_shape
scripts/feats/feat_to_shape.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/test_dev93/feats.scp dump/fbank_pitch/org/test_dev93/feats_shape
scripts/feats/feat_to_shape.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/test_dev93/feats.scp dump/fbank_pitch/org/test_dev93/feats_shape
scripts/feats/feat_to_shape.sh --nj 32 --cmd run.pl dump/fbank_pitch/test_eval92/feats.scp dump/fbank_pitch/test_eval92/feats_shape
/afs/cs.pitt.edu/usr0/ras306/miniconda3/envs/psinet/bin/python3 /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/bin/tokenize_text.py --token_type char --input dump/fbank_pitch/lm_train.txt --output data/token_list/char/tokens.txt --non_linguistic_symbols data/nlsyms.txt --field 2- --cleaner none --g2p none --write_vocabulary true --add_symbol '<blank>:0' --add_symbol '<unk>:1' --add_symbol '<sos/eos>:-1'
2020-11-27 20:50:26,404 (tokenize_text:171) INFO: OOV rate = 0.0 %
/afs/cs.pitt.edu/usr0/ras306/miniconda3/envs/psinet/bin/python3 /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/bin/aggregate_stats_dirs.py --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.1 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.2 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.3 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.4 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.5 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.6 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.7 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.8 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.9 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.10 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.11 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.12 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.13 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.14 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.15 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.16 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.17 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.18 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.19 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.20 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.21 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.22 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.23 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.24 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.25 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.26 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.27 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.28 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.29 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.30 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.31 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.32 --output_dir exp/asr_stats_fbank_pitch_char
2020-11-27 20:51:53,100 (launch:95) INFO: /afs/cs.pitt.edu/usr0/ras306/miniconda3/envs/psinet/bin/python3 /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/bin/launch.py --cmd 'run.pl --name exp/asr_train_asr_transformer_fbank_pitch_char/train.log' --log exp/asr_train_asr_transformer_fbank_pitch_char/train.log --ngpu 1 --num_nodes 1 --init_file_prefix exp/asr_train_asr_transformer_fbank_pitch_char/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel none --token_type char --token_list data/token_list/char/tokens.txt --non_linguistic_symbols data/nlsyms.txt --cleaner none --g2p none --valid_data_path_and_name_and_type dump/fbank_pitch/test_dev93/feats.scp,speech,kaldi_ark --valid_data_path_and_name_and_type dump/fbank_pitch/test_dev93/text,text,text --valid_shape_file exp/asr_stats_fbank_pitch_char/valid/speech_shape --valid_shape_file exp/asr_stats_fbank_pitch_char/valid/text_shape.char --resume true --fold_length 800 --fold_length 150 --output_dir exp/asr_train_asr_transformer_fbank_pitch_char --config conf/train_asr_transformer.yaml --input_size=48 --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_fbank_pitch_char/train/feats_stats.npz --train_data_path_and_name_and_type dump/fbank_pitch/train_si84/feats.scp,speech,kaldi_ark --train_data_path_and_name_and_type dump/fbank_pitch/train_si84/text,text,text --train_shape_file exp/asr_stats_fbank_pitch_char/train/speech_shape --train_shape_file exp/asr_stats_fbank_pitch_char/train/text_shape.char
2020-11-27 20:51:53,163 (launch:349) INFO: log file: exp/asr_train_asr_transformer_fbank_pitch_char/train.log
run.pl: job failed, log is in exp/asr_train_asr_transformer_fbank_pitch_char/train.log
Command '['run.pl', '--name', 'exp/asr_train_asr_transformer_fbank_pitch_char/train.log', '--gpu', '1', 'exp/asr_train_asr_transformer_fbank_pitch_char/train.log', 'python3', '-m', 'espnet2.bin.asr_train', '--use_preprocessor', 'true', '--bpemodel', 'none', '--token_type', 'char', '--token_list', 'data/token_list/char/tokens.txt', '--non_linguistic_symbols', 'data/nlsyms.txt', '--cleaner', 'none', '--g2p', 'none', '--valid_data_path_and_name_and_type', 'dump/fbank_pitch/test_dev93/feats.scp,speech,kaldi_ark', '--valid_data_path_and_name_and_type', 'dump/fbank_pitch/test_dev93/text,text,text', '--valid_shape_file', 'exp/asr_stats_fbank_pitch_char/valid/speech_shape', '--valid_shape_file', 'exp/asr_stats_fbank_pitch_char/valid/text_shape.char', '--resume', 'true', '--fold_length', '800', '--fold_length', '150', '--output_dir', 'exp/asr_train_asr_transformer_fbank_pitch_char', '--config', 'conf/train_asr_transformer.yaml', '--input_size=48', '--normalize=global_mvn', '--normalize_conf', 'stats_file=exp/asr_stats_fbank_pitch_char/train/feats_stats.npz', '--train_data_path_and_name_and_type', 'dump/fbank_pitch/train_si84/feats.scp,speech,kaldi_ark', '--train_data_path_and_name_and_type', 'dump/fbank_pitch/train_si84/text,text,text', '--train_shape_file', 'exp/asr_stats_fbank_pitch_char/train/speech_shape', '--train_shape_file', 'exp/asr_stats_fbank_pitch_char/train/text_shape.char', '--ngpu', '1', '--multiprocessing_distributed', 'True']' returned non-zero exit status 1.
Traceback (most recent call last):
  File "/afs/cs.pitt.edu/usr0/ras306/miniconda3/envs/psinet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/afs/cs.pitt.edu/usr0/ras306/miniconda3/envs/psinet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/bin/launch.py", line 385, in <module>
    main()
  File "/afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/bin/launch.py", line 378, in main
    f"###################\n" + "".join(lines[-1000:])
RuntimeError: 
################### The last 1000 lines of exp/asr_train_asr_transformer_fbank_pitch_char/train.log ###################
# python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel none --token_type char --token_list data/token_list/char/tokens.txt --non_linguistic_symbols data/nlsyms.txt --cleaner none --g2p none --valid_data_path_and_name_and_type dump/fbank_pitch/test_dev93/feats.scp,speech,kaldi_ark --valid_data_path_and_name_and_type dump/fbank_pitch/test_dev93/text,text,text --valid_shape_file exp/asr_stats_fbank_pitch_char/valid/speech_shape --valid_shape_file exp/asr_stats_fbank_pitch_char/valid/text_shape.char --resume true --fold_length 800 --fold_length 150 --output_dir exp/asr_train_asr_transformer_fbank_pitch_char --config conf/train_asr_transformer.yaml --input_size=48 --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_fbank_pitch_char/train/feats_stats.npz --train_data_path_and_name_and_type dump/fbank_pitch/train_si84/feats.scp,speech,kaldi_ark --train_data_path_and_name_and_type dump/fbank_pitch/train_si84/text,text,text --train_shape_file exp/asr_stats_fbank_pitch_char/train/speech_shape --train_shape_file exp/asr_stats_fbank_pitch_char/train/text_shape.char --ngpu 1 --multiprocessing_distributed True 
# Started at Fri Nov 27 20:51:53 EST 2020
#
/afs/cs.pitt.edu/usr0/ras306/miniconda3/envs/psinet/bin/python3 /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/bin/asr_train.py --use_preprocessor true --bpemodel none --token_type char --token_list data/token_list/char/tokens.txt --non_linguistic_symbols data/nlsyms.txt --cleaner none --g2p none --valid_data_path_and_name_and_type dump/fbank_pitch/test_dev93/feats.scp,speech,kaldi_ark --valid_data_path_and_name_and_type dump/fbank_pitch/test_dev93/text,text,text --valid_shape_file exp/asr_stats_fbank_pitch_char/valid/speech_shape --valid_shape_file exp/asr_stats_fbank_pitch_char/valid/text_shape.char --resume true --fold_length 800 --fold_length 150 --output_dir exp/asr_train_asr_transformer_fbank_pitch_char --config conf/train_asr_transformer.yaml --input_size=48 --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_fbank_pitch_char/train/feats_stats.npz --train_data_path_and_name_and_type dump/fbank_pitch/train_si84/feats.scp,speech,kaldi_ark --train_data_path_and_name_and_type dump/fbank_pitch/train_si84/text,text,text --train_shape_file exp/asr_stats_fbank_pitch_char/train/speech_shape --train_shape_file exp/asr_stats_fbank_pitch_char/train/text_shape.char --ngpu 1 --multiprocessing_distributed True
[magnolia] 2020-11-27 20:51:56,292 (asr:283) INFO: Vocabulary size: 65
[magnolia] 2020-11-27 20:52:57,098 (abs_task:1068) INFO: pytorch.version=1.4.0, cuda.available=True, cudnn.version=7603, cudnn.benchmark=False, cudnn.deterministic=True
[magnolia] 2020-11-27 20:52:57,107 (abs_task:1069) INFO: Model structure:
ESPnetASRModel(
  (normalize): GlobalMVN(stats_file=exp/asr_stats_fbank_pitch_char/train/feats_stats.npz, norm_means=True, norm_vars=True)
  (encoder): TransformerEncoder(
    (embed): Conv2dSubsampling(
      (conv): Sequential(
        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=2816, out_features=256, bias=True)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (encoders): MultiSequential(
      (0): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (2): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (3): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (4): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (5): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (6): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (7): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (8): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (9): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (10): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (11): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (embed): Sequential(
      (0): Embedding(65, 256)
      (1): PositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
    (output_layer): Linear(in_features=256, out_features=65, bias=True)
    (decoders): MultiSequential(
      (0): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (2): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (3): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (4): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (5): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=256, out_features=65, bias=True)
    (ctc_loss): CTCLoss()
  )
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
)

Model summary:
    Class Name: ESPnetASRModel
    Number of parameters: 26.62 M
    Size: 106.47 MB
    Type: torch.float32
[magnolia] 2020-11-27 20:52:57,109 (abs_task:1072) INFO: Optimizer:
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.005
    lr: 1.6666666666666665e-07
    weight_decay: 0
)
[magnolia] 2020-11-27 20:52:57,109 (abs_task:1073) INFO: Scheduler: WarmupLR(warmup_steps=30000)
[magnolia] 2020-11-27 20:52:57,113 (abs_task:1083) INFO: Saving the configuration in exp/asr_train_asr_transformer_fbank_pitch_char/config.yaml
Traceback (most recent call last):
  File "/afs/cs.pitt.edu/usr0/ras306/miniconda3/envs/psinet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/afs/cs.pitt.edu/usr0/ras306/miniconda3/envs/psinet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/bin/asr_train.py", line 23, in <module>
    main()
  File "/afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/bin/asr_train.py", line 19, in main
    ASRTask.main(cmd=cmd)
  File "/afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/tasks/abs_task.py", line 941, in main
    cls.main_worker(args)
  File "/afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/tasks/abs_task.py", line 1122, in main_worker
    ngpu=args.ngpu,
  File "/afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/tasks/abs_task.py", line 899, in resume
    model.load_state_dict(states["model"])
  File "/afs/cs.pitt.edu/usr0/ras306/miniconda3/envs/psinet/lib/python3.7/site-packages/torch/nn/modules/module.py", line 830, in load_state_dict
    self.__class__.__name__, "\n\t".join(error_msgs)))
RuntimeError: Error(s) in loading state_dict for ESPnetASRModel:
	size mismatch for normalize.mean: copying a param with shape torch.Size([26]) from checkpoint, the shape in current model is torch.Size([48]).
	size mismatch for normalize.std: copying a param with shape torch.Size([26]) from checkpoint, the shape in current model is torch.Size([48]).
	size mismatch for encoder.embed.out.0.weight: copying a param with shape torch.Size([256, 1280]) from checkpoint, the shape in current model is torch.Size([256, 2816]).
# Accounting: time=99 threads=1
# Ended (code 1) at Fri Nov 27 20:53:32 EST 2020, elapsed time 99 seconds

2020-11-27T20:53:32 (asr.sh:214:main) ./asr.sh --lang en --use_lm false --token_type char --nbpe 80 --nlsyms_txt data/nlsyms.txt --lm_config conf/train_lm_transformer.yaml --asr_config conf/train_asr_transformer.yaml --inference_config conf/decode.yaml --train_set train_si84 --valid_set test_dev93 --test_sets test_dev93 test_eval92 --bpe_train_text data/train_si284/text --lm_train_text data/train_si284/text data/local/other_text/text --ngpu 1 --feats_type fbank_pitch
2020-11-27T20:53:33 (asr.sh:364:main) Stage 1: Data preparation for data/train_si84, data/test_dev93, etc.
2020-11-27T20:53:33 (data.sh:37:main) local/wsj_data_prep.sh /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_1/??-{?,??}.? /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/??-{?,??}.?
Data preparation succeeded
2020-11-27T20:53:40 (data.sh:39:main) local/wsj_format_data.sh
local/wsj_format_data.sh 
Preparing train and test data
Succeeded in formatting data.
2020-11-27T20:53:42 (data.sh:43:main) Prepare text from lng_modl dir: /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/13-32.1/wsj1/doc/lng_modl/lm_train/np_data/{87,88,89}/*.z -> data/local/other_text/text
Data preparation succeeded
2020-11-27T20:54:04 (data.sh:39:main) local/wsj_format_data.sh
local/wsj_format_data.sh 
Preparing train and test data
Succeeded in formatting data.
2020-11-27T20:54:08 (data.sh:43:main) Prepare text from lng_modl dir: /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/13-32.1/wsj1/doc/lng_modl/lm_train/np_data/{87,88,89}/*.z -> data/local/other_text/text
2020-11-27T20:54:13 (data.sh:53:main) Create non linguistic symbols: data/nlsyms.txt
<*IN*>
<*MR.*>
<NOISE>
2020-11-27T20:54:13 (asr.sh:383:main) Skip stage 2: Speed perturbation
2020-11-27T20:54:13 (asr.sh:429:main) [Require Kaldi] Stage 3: fbank_pitch extract: data/ -> dump/fbank_pitch
utils/copy_data_dir.sh: copied data from data/train_si84 to dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
2020-11-27T20:54:59 (data.sh:53:main) Create non linguistic symbols: data/nlsyms.txt
<*IN*>
<*MR.*>
<NOISE>
2020-11-27T20:55:00 (asr.sh:383:main) Skip stage 2: Speed perturbation
2020-11-27T20:55:00 (asr.sh:429:main) [Require Kaldi] Stage 3: fbank_pitch extract: data/ -> dump/fbank_pitch
utils/copy_data_dir.sh: copied data from data/train_si84 to dump/fbank_pitch/org/train_si84
utils/copy_data_dir.sh: file feats.scp exists in dest dump/fbank_pitch/org/train_si84 but not in src data/train_si84.  Moving it to
 ... dump/fbank_pitch/org/train_si84/.backup/feats.scp
utils/copy_data_dir.sh: file utt2dur exists in dest dump/fbank_pitch/org/train_si84 but not in src data/train_si84.  Moving it to
 ... dump/fbank_pitch/org/train_si84/.backup/utt2dur
utils/copy_data_dir.sh: file utt2num_frames exists in dest dump/fbank_pitch/org/train_si84 but not in src data/train_si84.  Moving it to
 ... dump/fbank_pitch/org/train_si84/.backup/utt2num_frames
utils/copy_data_dir.sh: file frame_shift exists in dest dump/fbank_pitch/org/train_si84 but not in src data/train_si84.  Moving it to
 ... dump/fbank_pitch/org/train_si84/.backup/frame_shift
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
2020-11-27T20:55:18 (asr.sh:214:main) ./asr.sh --lang en --use_lm false --token_type char --nbpe 80 --nlsyms_txt data/nlsyms.txt --lm_config conf/train_lm_transformer.yaml --asr_config conf/train_asr_transformer.yaml --inference_config conf/decode.yaml --train_set train_si84 --valid_set test_dev93 --test_sets test_dev93 test_eval92 --bpe_train_text data/train_si284/text --lm_train_text data/train_si284/text data/local/other_text/text --ngpu 1 --feats_type fbank_pitch
2020-11-27T20:55:18 (asr.sh:364:main) Stage 1: Data preparation for data/train_si84, data/test_dev93, etc.
2020-11-27T20:55:18 (data.sh:37:main) local/wsj_data_prep.sh /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_1/??-{?,??}.? /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/??-{?,??}.?
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_fbank_pitch.sh: Succeeded creating filterbank and pitch features for train_si84
fix_data_dir.sh: kept all 7138 utterances.
fix_data_dir.sh: old files are kept in dump/fbank_pitch/org/train_si84/.backup
utils/copy_data_dir.sh: copied data from data/test_dev93 to dump/fbank_pitch/org/test_dev93
utils/copy_data_dir.sh: file feats.scp exists in dest dump/fbank_pitch/org/test_dev93 but not in src data/test_dev93.  Moving it to
 ... dump/fbank_pitch/org/test_dev93/.backup/feats.scp
utils/copy_data_dir.sh: file utt2dur exists in dest dump/fbank_pitch/org/test_dev93 but not in src data/test_dev93.  Moving it to
 ... dump/fbank_pitch/org/test_dev93/.backup/utt2dur
utils/copy_data_dir.sh: file utt2num_frames exists in dest dump/fbank_pitch/org/test_dev93 but not in src data/test_dev93.  Moving it to
 ... dump/fbank_pitch/org/test_dev93/.backup/utt2num_frames
utils/copy_data_dir.sh: file frame_shift exists in dest dump/fbank_pitch/org/test_dev93 but not in src data/test_dev93.  Moving it to
 ... dump/fbank_pitch/org/test_dev93/.backup/frame_shift
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/test_dev93
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/test_dev93
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/test_dev93
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_fbank_pitch.sh: Succeeded creating filterbank and pitch features for test_dev93
fix_data_dir.sh: kept all 503 utterances.
fix_data_dir.sh: old files are kept in dump/fbank_pitch/org/test_dev93/.backup
utils/copy_data_dir.sh: copied data from data/test_dev93 to dump/fbank_pitch/org/test_dev93
utils/copy_data_dir.sh: file feats.scp exists in dest dump/fbank_pitch/org/test_dev93 but not in src data/test_dev93.  Moving it to
 ... dump/fbank_pitch/org/test_dev93/.backup/feats.scp
utils/copy_data_dir.sh: file utt2dur exists in dest dump/fbank_pitch/org/test_dev93 but not in src data/test_dev93.  Moving it to
 ... dump/fbank_pitch/org/test_dev93/.backup/utt2dur
utils/copy_data_dir.sh: file utt2num_frames exists in dest dump/fbank_pitch/org/test_dev93 but not in src data/test_dev93.  Moving it to
 ... dump/fbank_pitch/org/test_dev93/.backup/utt2num_frames
utils/copy_data_dir.sh: file frame_shift exists in dest dump/fbank_pitch/org/test_dev93 but not in src data/test_dev93.  Moving it to
 ... dump/fbank_pitch/org/test_dev93/.backup/frame_shift
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/test_dev93
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/test_dev93
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/test_dev93
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_fbank_pitch.sh: Succeeded creating filterbank and pitch features for test_dev93
fix_data_dir.sh: kept all 503 utterances.
fix_data_dir.sh: old files are kept in dump/fbank_pitch/org/test_dev93/.backup
Data preparation succeeded
2020-11-27T20:56:52 (data.sh:39:main) local/wsj_format_data.sh
local/wsj_format_data.sh 
utils/copy_data_dir.sh: copied data from data/test_eval92 to dump/fbank_pitch/test_eval92
utils/copy_data_dir.sh: file feats.scp exists in dest dump/fbank_pitch/test_eval92 but not in src data/test_eval92.  Moving it to
 ... dump/fbank_pitch/test_eval92/.backup/feats.scp
utils/copy_data_dir.sh: file utt2dur exists in dest dump/fbank_pitch/test_eval92 but not in src data/test_eval92.  Moving it to
 ... dump/fbank_pitch/test_eval92/.backup/utt2dur
utils/copy_data_dir.sh: file utt2num_frames exists in dest dump/fbank_pitch/test_eval92 but not in src data/test_eval92.  Moving it to
 ... dump/fbank_pitch/test_eval92/.backup/utt2num_frames
utils/copy_data_dir.sh: file frame_shift exists in dest dump/fbank_pitch/test_eval92 but not in src data/test_eval92.  Moving it to
 ... dump/fbank_pitch/test_eval92/.backup/frame_shift
Preparing train and test data
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/test_eval92
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/test_eval92
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/test_eval92
Succeeded in formatting data.
2020-11-27T20:56:54 (data.sh:43:main) Prepare text from lng_modl dir: /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/13-32.1/wsj1/doc/lng_modl/lm_train/np_data/{87,88,89}/*.z -> data/local/other_text/text
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_fbank_pitch.sh: Succeeded creating filterbank and pitch features for test_eval92
fix_data_dir.sh: kept all 333 utterances.
fix_data_dir.sh: old files are kept in dump/fbank_pitch/test_eval92/.backup
2020-11-27T20:57:05 (asr.sh:490:main) Stage 4: Remove long/short data: dump/fbank_pitch/org -> dump/fbank_pitch
utils/copy_data_dir.sh: copied data from dump/fbank_pitch/org/train_si84 to dump/fbank_pitch/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/train_si84
fix_data_dir.sh: kept 7137 utterances out of 7138
fix_data_dir.sh: old files are kept in dump/fbank_pitch/train_si84/.backup
utils/copy_data_dir.sh: copied data from dump/fbank_pitch/org/test_dev93 to dump/fbank_pitch/test_dev93
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/test_dev93
fix_data_dir.sh: kept all 503 utterances.
fix_data_dir.sh: old files are kept in dump/fbank_pitch/test_dev93/.backup
2020-11-27T20:57:35 (data.sh:53:main) Create non linguistic symbols: data/nlsyms.txt
<*IN*>
<*MR.*>
<NOISE>
2020-11-27T20:57:35 (asr.sh:383:main) Skip stage 2: Speed perturbation
2020-11-27T20:57:35 (asr.sh:429:main) [Require Kaldi] Stage 3: fbank_pitch extract: data/ -> dump/fbank_pitch
utils/copy_data_dir.sh: copied data from data/train_si84 to dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
2020-11-27T20:57:58 (asr.sh:585:main) Stage 5: Generate character level token_list from data/train_si284/text data/local/other_text/text
2020-11-27T20:58:36 (asr.sh:214:main) ./asr.sh --lang en --use_lm false --token_type char --nbpe 80 --nlsyms_txt data/nlsyms.txt --lm_config conf/train_lm_transformer.yaml --asr_config conf/train_asr_transformer.yaml --inference_config conf/decode.yaml --train_set train_si84 --valid_set test_dev93 --test_sets test_dev93 test_eval92 --bpe_train_text data/train_si284/text --lm_train_text data/train_si284/text data/local/other_text/text --ngpu 1 --feats_type fbank_pitch
2020-11-27T20:58:37 (asr.sh:364:main) Stage 1: Data preparation for data/train_si84, data/test_dev93, etc.
2020-11-27T20:58:37 (data.sh:37:main) local/wsj_data_prep.sh /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_1/??-{?,??}.? /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/??-{?,??}.?
Data preparation succeeded
2020-11-27T20:58:52 (data.sh:39:main) local/wsj_format_data.sh
local/wsj_format_data.sh 
Preparing train and test data
Succeeded in formatting data.
2020-11-27T20:58:54 (data.sh:43:main) Prepare text from lng_modl dir: /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/13-32.1/wsj1/doc/lng_modl/lm_train/np_data/{87,88,89}/*.z -> data/local/other_text/text
2020-11-27T20:59:19 (data.sh:53:main) Create non linguistic symbols: data/nlsyms.txt
<*IN*>
<*MR.*>
<NOISE>
2020-11-27T20:59:20 (asr.sh:383:main) Skip stage 2: Speed perturbation
2020-11-27T20:59:20 (asr.sh:429:main) [Require Kaldi] Stage 3: fbank_pitch extract: data/ -> dump/fbank_pitch
utils/copy_data_dir.sh: copied data from data/train_si84 to dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
2020-11-27T21:00:19 (asr.sh:214:main) ./asr.sh --lang en --use_lm false --token_type char --nbpe 80 --nlsyms_txt data/nlsyms.txt --lm_config conf/train_lm_transformer.yaml --asr_config conf/train_asr_transformer.yaml --inference_config conf/decode.yaml --train_set train_si84 --valid_set test_dev93 --test_sets test_dev93 test_eval92 --bpe_train_text data/train_si284/text --lm_train_text data/train_si284/text data/local/other_text/text --ngpu 1 --feats_type fbank_pitch
2020-11-27T21:00:19 (asr.sh:364:main) Stage 1: Data preparation for data/train_si84, data/test_dev93, etc.
2020-11-27T21:00:19 (data.sh:37:main) local/wsj_data_prep.sh /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_1/??-{?,??}.? /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/??-{?,??}.?
Data preparation succeeded
2020-11-27T21:00:34 (data.sh:39:main) local/wsj_format_data.sh
local/wsj_format_data.sh 
Preparing train and test data
Succeeded in formatting data.
2020-11-27T21:00:36 (data.sh:43:main) Prepare text from lng_modl dir: /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/13-32.1/wsj1/doc/lng_modl/lm_train/np_data/{87,88,89}/*.z -> data/local/other_text/text
2020-11-27T21:01:03 (data.sh:53:main) Create non linguistic symbols: data/nlsyms.txt
<*IN*>
<*MR.*>
<NOISE>
2020-11-27T21:01:03 (asr.sh:383:main) Skip stage 2: Speed perturbation
2020-11-27T21:01:03 (asr.sh:429:main) [Require Kaldi] Stage 3: fbank_pitch extract: data/ -> dump/fbank_pitch
utils/copy_data_dir.sh: copied data from data/train_si84 to dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
2020-11-27T21:02:00 (asr.sh:214:main) ./asr.sh --lang en --use_lm false --token_type char --nbpe 80 --nlsyms_txt data/nlsyms.txt --lm_config conf/train_lm_transformer.yaml --asr_config conf/train_asr_transformer.yaml --inference_config conf/decode.yaml --train_set train_si84 --valid_set test_dev93 --test_sets test_dev93 test_eval92 --bpe_train_text data/train_si284/text --lm_train_text data/train_si284/text data/local/other_text/text --ngpu 1 --feats_type fbank_pitch
2020-11-27T21:02:01 (asr.sh:364:main) Stage 1: Data preparation for data/train_si84, data/test_dev93, etc.
2020-11-27T21:02:01 (data.sh:37:main) local/wsj_data_prep.sh /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_1/??-{?,??}.? /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/??-{?,??}.?
2020-11-27T21:02:09 (asr.sh:806:main) Stage 6-8: Skip lm-related stages: use_lm=false
2020-11-27T21:02:09 (asr.sh:813:main) Stage 9: ASR collect stats: train_set=dump/fbank_pitch/train_si84, valid_set=dump/fbank_pitch/test_dev93
2020-11-27T21:02:09 (asr.sh:863:main) Generate 'exp/asr_stats_fbank_pitch_char/run.sh'. You can resume the process from stage 9 using this script
2020-11-27T21:02:09 (asr.sh:867:main) ASR collect-stats started... log: 'exp/asr_stats_fbank_pitch_char/logdir/stats.*.log'
2020-11-27T21:02:26 (asr.sh:914:main) Stage 10: ASR Training: train_set=dump/fbank_pitch/train_si84, valid_set=dump/fbank_pitch/test_dev93
2020-11-27T21:02:26 (asr.sh:981:main) Generate 'exp/asr_train_asr_transformer_fbank_pitch_char/run.sh'. You can resume the process from stage 10 using this script
2020-11-27T21:02:26 (asr.sh:985:main) ASR training started... log: 'exp/asr_train_asr_transformer_fbank_pitch_char/train.log'
Data preparation succeeded
2020-11-27T21:02:26 (data.sh:39:main) local/wsj_format_data.sh
local/wsj_format_data.sh 
Preparing train and test data
Succeeded in formatting data.
2020-11-27T21:02:28 (data.sh:43:main) Prepare text from lng_modl dir: /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/13-32.1/wsj1/doc/lng_modl/lm_train/np_data/{87,88,89}/*.z -> data/local/other_text/text

Failed a run
RUNNING:


run.pl: 32 / 32 failed, log is in dump/fbank_pitch/org/train_si84/log/make_fbank_pitch_train_si84.*.log

Failed a run
RUNNING:-dup


run.pl: 32 / 32 failed, log is in dump/fbank_pitch/org/train_si84/log/make_fbank_pitch_train_si84.*.log

Failed a run
RUNNING:-dup


run.pl: 32 / 32 failed, log is in dump/fbank_pitch/org/train_si84/log/make_fbank_pitch_train_si84.*.log

Failed a run
RUNNING:-dup


run.pl: 32 / 32 failed, log is in dump/fbank_pitch/org/train_si84/log/make_fbank_pitch_train_si84.*.log

Failed a run
RUNNING:-dup


scripts/feats/feat_to_shape.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/train_si84/feats.scp dump/fbank_pitch/org/train_si84/feats_shape
scripts/feats/feat_to_shape.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/test_dev93/feats.scp dump/fbank_pitch/org/test_dev93/feats_shape
scripts/feats/feat_to_shape.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/test_dev93/feats.scp dump/fbank_pitch/org/test_dev93/feats_shape
scripts/feats/feat_to_shape.sh --nj 32 --cmd run.pl dump/fbank_pitch/test_eval92/feats.scp dump/fbank_pitch/test_eval92/feats_shape
/afs/cs.pitt.edu/usr0/ras306/miniconda3/envs/psinet/bin/python3 /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/bin/tokenize_text.py --token_type char --input dump/fbank_pitch/lm_train.txt --output data/token_list/char/tokens.txt --non_linguistic_symbols data/nlsyms.txt --field 2- --cleaner none --g2p none --write_vocabulary true --add_symbol '<blank>:0' --add_symbol '<unk>:1' --add_symbol '<sos/eos>:-1'
2020-11-27 21:02:09,319 (tokenize_text:171) INFO: OOV rate = 0.0 %
/afs/cs.pitt.edu/usr0/ras306/miniconda3/envs/psinet/bin/python3 /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/bin/aggregate_stats_dirs.py --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.1 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.2 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.3 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.4 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.5 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.6 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.7 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.8 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.9 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.10 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.11 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.12 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.13 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.14 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.15 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.16 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.17 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.18 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.19 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.20 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.21 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.22 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.23 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.24 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.25 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.26 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.27 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.28 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.29 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.30 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.31 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.32 --output_dir exp/asr_stats_fbank_pitch_char
2020-11-27 21:02:26,412 (launch:95) INFO: /afs/cs.pitt.edu/usr0/ras306/miniconda3/envs/psinet/bin/python3 /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/bin/launch.py --cmd 'run.pl --name exp/asr_train_asr_transformer_fbank_pitch_char/train.log' --log exp/asr_train_asr_transformer_fbank_pitch_char/train.log --ngpu 1 --num_nodes 1 --init_file_prefix exp/asr_train_asr_transformer_fbank_pitch_char/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel none --token_type char --token_list data/token_list/char/tokens.txt --non_linguistic_symbols data/nlsyms.txt --cleaner none --g2p none --valid_data_path_and_name_and_type dump/fbank_pitch/test_dev93/feats.scp,speech,kaldi_ark --valid_data_path_and_name_and_type dump/fbank_pitch/test_dev93/text,text,text --valid_shape_file exp/asr_stats_fbank_pitch_char/valid/speech_shape --valid_shape_file exp/asr_stats_fbank_pitch_char/valid/text_shape.char --resume true --fold_length 800 --fold_length 150 --output_dir exp/asr_train_asr_transformer_fbank_pitch_char --config conf/train_asr_transformer.yaml --input_size=23 --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_fbank_pitch_char/train/feats_stats.npz --train_data_path_and_name_and_type dump/fbank_pitch/train_si84/feats.scp,speech,kaldi_ark --train_data_path_and_name_and_type dump/fbank_pitch/train_si84/text,text,text --train_shape_file exp/asr_stats_fbank_pitch_char/train/speech_shape --train_shape_file exp/asr_stats_fbank_pitch_char/train/text_shape.char
2020-11-27 21:02:26,452 (launch:349) INFO: log file: exp/asr_train_asr_transformer_fbank_pitch_char/train.log
run.pl: job failed, log is in exp/asr_train_asr_transformer_fbank_pitch_char/train.log
Command '['run.pl', '--name', 'exp/asr_train_asr_transformer_fbank_pitch_char/train.log', '--gpu', '1', 'exp/asr_train_asr_transformer_fbank_pitch_char/train.log', 'python3', '-m', 'espnet2.bin.asr_train', '--use_preprocessor', 'true', '--bpemodel', 'none', '--token_type', 'char', '--token_list', 'data/token_list/char/tokens.txt', '--non_linguistic_symbols', 'data/nlsyms.txt', '--cleaner', 'none', '--g2p', 'none', '--valid_data_path_and_name_and_type', 'dump/fbank_pitch/test_dev93/feats.scp,speech,kaldi_ark', '--valid_data_path_and_name_and_type', 'dump/fbank_pitch/test_dev93/text,text,text', '--valid_shape_file', 'exp/asr_stats_fbank_pitch_char/valid/speech_shape', '--valid_shape_file', 'exp/asr_stats_fbank_pitch_char/valid/text_shape.char', '--resume', 'true', '--fold_length', '800', '--fold_length', '150', '--output_dir', 'exp/asr_train_asr_transformer_fbank_pitch_char', '--config', 'conf/train_asr_transformer.yaml', '--input_size=23', '--normalize=global_mvn', '--normalize_conf', 'stats_file=exp/asr_stats_fbank_pitch_char/train/feats_stats.npz', '--train_data_path_and_name_and_type', 'dump/fbank_pitch/train_si84/feats.scp,speech,kaldi_ark', '--train_data_path_and_name_and_type', 'dump/fbank_pitch/train_si84/text,text,text', '--train_shape_file', 'exp/asr_stats_fbank_pitch_char/train/speech_shape', '--train_shape_file', 'exp/asr_stats_fbank_pitch_char/train/text_shape.char', '--ngpu', '1', '--multiprocessing_distributed', 'True']' returned non-zero exit status 1.
Traceback (most recent call last):
  File "/afs/cs.pitt.edu/usr0/ras306/miniconda3/envs/psinet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/afs/cs.pitt.edu/usr0/ras306/miniconda3/envs/psinet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/bin/launch.py", line 385, in <module>
    main()
  File "/afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/bin/launch.py", line 378, in main
    f"###################\n" + "".join(lines[-1000:])
RuntimeError: 
################### The last 1000 lines of exp/asr_train_asr_transformer_fbank_pitch_char/train.log ###################
# python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel none --token_type char --token_list data/token_list/char/tokens.txt --non_linguistic_symbols data/nlsyms.txt --cleaner none --g2p none --valid_data_path_and_name_and_type dump/fbank_pitch/test_dev93/feats.scp,speech,kaldi_ark --valid_data_path_and_name_and_type dump/fbank_pitch/test_dev93/text,text,text --valid_shape_file exp/asr_stats_fbank_pitch_char/valid/speech_shape --valid_shape_file exp/asr_stats_fbank_pitch_char/valid/text_shape.char --resume true --fold_length 800 --fold_length 150 --output_dir exp/asr_train_asr_transformer_fbank_pitch_char --config conf/train_asr_transformer.yaml --input_size=23 --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_fbank_pitch_char/train/feats_stats.npz --train_data_path_and_name_and_type dump/fbank_pitch/train_si84/feats.scp,speech,kaldi_ark --train_data_path_and_name_and_type dump/fbank_pitch/train_si84/text,text,text --train_shape_file exp/asr_stats_fbank_pitch_char/train/speech_shape --train_shape_file exp/asr_stats_fbank_pitch_char/train/text_shape.char --ngpu 1 --multiprocessing_distributed True 
# Started at Fri Nov 27 21:02:26 EST 2020
#
/afs/cs.pitt.edu/usr0/ras306/miniconda3/envs/psinet/bin/python3 /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/bin/asr_train.py --use_preprocessor true --bpemodel none --token_type char --token_list data/token_list/char/tokens.txt --non_linguistic_symbols data/nlsyms.txt --cleaner none --g2p none --valid_data_path_and_name_and_type dump/fbank_pitch/test_dev93/feats.scp,speech,kaldi_ark --valid_data_path_and_name_and_type dump/fbank_pitch/test_dev93/text,text,text --valid_shape_file exp/asr_stats_fbank_pitch_char/valid/speech_shape --valid_shape_file exp/asr_stats_fbank_pitch_char/valid/text_shape.char --resume true --fold_length 800 --fold_length 150 --output_dir exp/asr_train_asr_transformer_fbank_pitch_char --config conf/train_asr_transformer.yaml --input_size=23 --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_fbank_pitch_char/train/feats_stats.npz --train_data_path_and_name_and_type dump/fbank_pitch/train_si84/feats.scp,speech,kaldi_ark --train_data_path_and_name_and_type dump/fbank_pitch/train_si84/text,text,text --train_shape_file exp/asr_stats_fbank_pitch_char/train/speech_shape --train_shape_file exp/asr_stats_fbank_pitch_char/train/text_shape.char --ngpu 1 --multiprocessing_distributed True
[magnolia] 2020-11-27 21:02:28,129 (asr:283) INFO: Vocabulary size: 65
[magnolia] 2020-11-27 21:02:31,393 (abs_task:1068) INFO: pytorch.version=1.4.0, cuda.available=True, cudnn.version=7603, cudnn.benchmark=False, cudnn.deterministic=True
[magnolia] 2020-11-27 21:02:31,397 (abs_task:1069) INFO: Model structure:
ESPnetASRModel(
  (normalize): GlobalMVN(stats_file=exp/asr_stats_fbank_pitch_char/train/feats_stats.npz, norm_means=True, norm_vars=True)
  (encoder): TransformerEncoder(
    (embed): Conv2dSubsampling(
      (conv): Sequential(
        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=1280, out_features=256, bias=True)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (encoders): MultiSequential(
      (0): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (2): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (3): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (4): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (5): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (6): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (7): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (8): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (9): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (10): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (11): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (embed): Sequential(
      (0): Embedding(65, 256)
      (1): PositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
    (output_layer): Linear(in_features=256, out_features=65, bias=True)
    (decoders): MultiSequential(
      (0): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (2): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (3): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (4): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (5): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=256, out_features=65, bias=True)
    (ctc_loss): CTCLoss()
  )
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
)

Model summary:
    Class Name: ESPnetASRModel
    Number of parameters: 26.23 M
    Size: 104.9 MB
    Type: torch.float32
[magnolia] 2020-11-27 21:02:31,397 (abs_task:1072) INFO: Optimizer:
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.005
    lr: 1.6666666666666665e-07
    weight_decay: 0
)
[magnolia] 2020-11-27 21:02:31,397 (abs_task:1073) INFO: Scheduler: WarmupLR(warmup_steps=30000)
[magnolia] 2020-11-27 21:02:31,401 (abs_task:1083) INFO: Saving the configuration in exp/asr_train_asr_transformer_fbank_pitch_char/config.yaml
Traceback (most recent call last):
  File "/afs/cs.pitt.edu/usr0/ras306/miniconda3/envs/psinet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/afs/cs.pitt.edu/usr0/ras306/miniconda3/envs/psinet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/bin/asr_train.py", line 23, in <module>
    main()
  File "/afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/bin/asr_train.py", line 19, in main
    ASRTask.main(cmd=cmd)
  File "/afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/tasks/abs_task.py", line 941, in main
    cls.main_worker(args)
  File "/afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/tasks/abs_task.py", line 1122, in main_worker
    ngpu=args.ngpu,
  File "/afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/tasks/abs_task.py", line 899, in resume
    model.load_state_dict(states["model"])
  File "/afs/cs.pitt.edu/usr0/ras306/miniconda3/envs/psinet/lib/python3.7/site-packages/torch/nn/modules/module.py", line 830, in load_state_dict
    self.__class__.__name__, "\n\t".join(error_msgs)))
RuntimeError: Error(s) in loading state_dict for ESPnetASRModel:
	size mismatch for normalize.mean: copying a param with shape torch.Size([26]) from checkpoint, the shape in current model is torch.Size([23]).
	size mismatch for normalize.std: copying a param with shape torch.Size([26]) from checkpoint, the shape in current model is torch.Size([23]).
# Accounting: time=6 threads=1
# Ended (code 1) at Fri Nov 27 21:02:32 EST 2020, elapsed time 6 seconds

2020-11-27T21:02:32 (asr.sh:214:main) ./asr.sh --lang en --use_lm false --token_type char --nbpe 80 --nlsyms_txt data/nlsyms.txt --lm_config conf/train_lm_transformer.yaml --asr_config conf/train_asr_transformer.yaml --inference_config conf/decode.yaml --train_set train_si84 --valid_set test_dev93 --test_sets test_dev93 test_eval92 --bpe_train_text data/train_si284/text --lm_train_text data/train_si284/text data/local/other_text/text --ngpu 1 --feats_type fbank_pitch
2020-11-27T21:02:32 (asr.sh:364:main) Stage 1: Data preparation for data/train_si84, data/test_dev93, etc.
2020-11-27T21:02:32 (data.sh:37:main) local/wsj_data_prep.sh /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_1/??-{?,??}.? /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/??-{?,??}.?
2020-11-27T21:02:55 (data.sh:53:main) Create non linguistic symbols: data/nlsyms.txt
<*IN*>
<*MR.*>
<NOISE>
2020-11-27T21:02:56 (asr.sh:383:main) Skip stage 2: Speed perturbation
2020-11-27T21:02:56 (asr.sh:429:main) [Require Kaldi] Stage 3: fbank_pitch extract: data/ -> dump/fbank_pitch
utils/copy_data_dir.sh: copied data from data/train_si84 to dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
Data preparation succeeded
2020-11-27T21:03:19 (data.sh:39:main) local/wsj_format_data.sh
local/wsj_format_data.sh 
Preparing train and test data
Succeeded in formatting data.
2020-11-27T21:03:32 (data.sh:43:main) Prepare text from lng_modl dir: /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/13-32.1/wsj1/doc/lng_modl/lm_train/np_data/{87,88,89}/*.z -> data/local/other_text/text
2020-11-27T21:03:49 (asr.sh:214:main) ./asr.sh --lang en --use_lm false --token_type char --nbpe 80 --nlsyms_txt data/nlsyms.txt --lm_config conf/train_lm_transformer.yaml --asr_config conf/train_asr_transformer.yaml --inference_config conf/decode.yaml --train_set train_si84 --valid_set test_dev93 --test_sets test_dev93 test_eval92 --bpe_train_text data/train_si284/text --lm_train_text data/train_si284/text data/local/other_text/text --ngpu 1 --feats_type fbank_pitch
2020-11-27T21:03:50 (asr.sh:364:main) Stage 1: Data preparation for data/train_si84, data/test_dev93, etc.
2020-11-27T21:03:50 (data.sh:37:main) local/wsj_data_prep.sh /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_1/??-{?,??}.? /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/??-{?,??}.?
2020-11-27T21:04:08 (data.sh:53:main) Create non linguistic symbols: data/nlsyms.txt
<*IN*>
<*MR.*>
<NOISE>
2020-11-27T21:04:09 (asr.sh:383:main) Skip stage 2: Speed perturbation
2020-11-27T21:04:09 (asr.sh:429:main) [Require Kaldi] Stage 3: fbank_pitch extract: data/ -> dump/fbank_pitch
utils/copy_data_dir.sh: copied data from data/train_si84 to dump/fbank_pitch/org/train_si84
utils/copy_data_dir.sh: file feats.scp exists in dest dump/fbank_pitch/org/train_si84 but not in src data/train_si84.  Moving it to
 ... dump/fbank_pitch/org/train_si84/.backup/feats.scp
utils/copy_data_dir.sh: file utt2dur exists in dest dump/fbank_pitch/org/train_si84 but not in src data/train_si84.  Moving it to
 ... dump/fbank_pitch/org/train_si84/.backup/utt2dur
utils/copy_data_dir.sh: file utt2num_frames exists in dest dump/fbank_pitch/org/train_si84 but not in src data/train_si84.  Moving it to
 ... dump/fbank_pitch/org/train_si84/.backup/utt2num_frames
utils/copy_data_dir.sh: file frame_shift exists in dest dump/fbank_pitch/org/train_si84 but not in src data/train_si84.  Moving it to
 ... dump/fbank_pitch/org/train_si84/.backup/frame_shift
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
Data preparation succeeded
2020-11-27T21:04:41 (data.sh:39:main) local/wsj_format_data.sh
local/wsj_format_data.sh 
Preparing train and test data
Succeeded in formatting data.
2020-11-27T21:04:54 (data.sh:43:main) Prepare text from lng_modl dir: /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/13-32.1/wsj1/doc/lng_modl/lm_train/np_data/{87,88,89}/*.z -> data/local/other_text/text
2020-11-27T21:05:01 (asr.sh:214:main) ./asr.sh --lang en --use_lm false --token_type char --nbpe 80 --nlsyms_txt data/nlsyms.txt --lm_config conf/train_lm_transformer.yaml --asr_config conf/train_asr_transformer.yaml --inference_config conf/decode.yaml --train_set train_si84 --valid_set test_dev93 --test_sets test_dev93 test_eval92 --bpe_train_text data/train_si284/text --lm_train_text data/train_si284/text data/local/other_text/text --ngpu 1 --feats_type fbank_pitch
2020-11-27T21:05:02 (asr.sh:364:main) Stage 1: Data preparation for data/train_si84, data/test_dev93, etc.
2020-11-27T21:05:02 (data.sh:37:main) local/wsj_data_prep.sh /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_1/??-{?,??}.? /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/??-{?,??}.?
2020-11-27T21:05:26 (data.sh:53:main) Create non linguistic symbols: data/nlsyms.txt
<*IN*>
<*MR.*>
<NOISE>
2020-11-27T21:05:27 (asr.sh:383:main) Skip stage 2: Speed perturbation
2020-11-27T21:05:27 (asr.sh:429:main) [Require Kaldi] Stage 3: fbank_pitch extract: data/ -> dump/fbank_pitch
utils/copy_data_dir.sh: copied data from data/train_si84 to dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
Data preparation succeeded
2020-11-27T21:05:38 (data.sh:39:main) local/wsj_format_data.sh
local/wsj_format_data.sh 
Preparing train and test data
Succeeded in formatting data.
2020-11-27T21:05:45 (data.sh:43:main) Prepare text from lng_modl dir: /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/13-32.1/wsj1/doc/lng_modl/lm_train/np_data/{87,88,89}/*.z -> data/local/other_text/text
2020-11-27T21:06:14 (asr.sh:214:main) ./asr.sh --lang en --use_lm false --token_type char --nbpe 80 --nlsyms_txt data/nlsyms.txt --lm_config conf/train_lm_transformer.yaml --asr_config conf/train_asr_transformer.yaml --inference_config conf/decode.yaml --train_set train_si84 --valid_set test_dev93 --test_sets test_dev93 test_eval92 --bpe_train_text data/train_si284/text --lm_train_text data/train_si284/text data/local/other_text/text --ngpu 1 --feats_type fbank_pitch
2020-11-27T21:06:15 (asr.sh:364:main) Stage 1: Data preparation for data/train_si84, data/test_dev93, etc.
2020-11-27T21:06:15 (data.sh:37:main) local/wsj_data_prep.sh /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_1/??-{?,??}.? /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/??-{?,??}.?
2020-11-27T21:06:23 (data.sh:53:main) Create non linguistic symbols: data/nlsyms.txt
<*IN*>
<*MR.*>
<NOISE>
2020-11-27T21:06:24 (asr.sh:383:main) Skip stage 2: Speed perturbation
2020-11-27T21:06:24 (asr.sh:429:main) [Require Kaldi] Stage 3: fbank_pitch extract: data/ -> dump/fbank_pitch
utils/copy_data_dir.sh: copied data from data/train_si84 to dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
2020-11-27T21:07:11 (asr.sh:214:main) ./asr.sh --lang en --use_lm false --token_type char --nbpe 80 --nlsyms_txt data/nlsyms.txt --lm_config conf/train_lm_transformer.yaml --asr_config conf/train_asr_transformer.yaml --inference_config conf/decode.yaml --train_set train_si84 --valid_set test_dev93 --test_sets test_dev93 test_eval92 --bpe_train_text data/train_si284/text --lm_train_text data/train_si284/text data/local/other_text/text --ngpu 1 --feats_type fbank_pitch
2020-11-27T21:07:11 (asr.sh:364:main) Stage 1: Data preparation for data/train_si84, data/test_dev93, etc.
2020-11-27T21:07:11 (data.sh:37:main) local/wsj_data_prep.sh /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_1/??-{?,??}.? /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/??-{?,??}.?
Data preparation succeeded
2020-11-27T21:07:15 (data.sh:39:main) local/wsj_format_data.sh
local/wsj_format_data.sh 
Preparing train and test data
Succeeded in formatting data.
2020-11-27T21:07:17 (data.sh:43:main) Prepare text from lng_modl dir: /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/13-32.1/wsj1/doc/lng_modl/lm_train/np_data/{87,88,89}/*.z -> data/local/other_text/text
2020-11-27T21:07:46 (data.sh:53:main) Create non linguistic symbols: data/nlsyms.txt
Data preparation succeeded
2020-11-27T21:07:46 (data.sh:39:main) local/wsj_format_data.sh
local/wsj_format_data.sh 
<*IN*>
<*MR.*>
<NOISE>
2020-11-27T21:07:46 (asr.sh:383:main) Skip stage 2: Speed perturbation
2020-11-27T21:07:46 (asr.sh:429:main) [Require Kaldi] Stage 3: fbank_pitch extract: data/ -> dump/fbank_pitch
Preparing train and test data
utils/copy_data_dir.sh: copied data from data/train_si84 to dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
Succeeded in formatting data.
2020-11-27T21:07:48 (data.sh:43:main) Prepare text from lng_modl dir: /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/13-32.1/wsj1/doc/lng_modl/lm_train/np_data/{87,88,89}/*.z -> data/local/other_text/text
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
2020-11-27T21:07:53 (asr.sh:214:main) ./asr.sh --lang en --use_lm false --token_type char --nbpe 80 --nlsyms_txt data/nlsyms.txt --lm_config conf/train_lm_transformer.yaml --asr_config conf/train_asr_transformer.yaml --inference_config conf/decode.yaml --train_set train_si84 --valid_set test_dev93 --test_sets test_dev93 test_eval92 --bpe_train_text data/train_si284/text --lm_train_text data/train_si284/text data/local/other_text/text --ngpu 1 --feats_type fbank_pitch
2020-11-27T21:07:54 (asr.sh:364:main) Stage 1: Data preparation for data/train_si84, data/test_dev93, etc.
2020-11-27T21:07:54 (data.sh:37:main) local/wsj_data_prep.sh /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_1/??-{?,??}.? /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/??-{?,??}.?
2020-11-27T21:08:16 (data.sh:53:main) Create non linguistic symbols: data/nlsyms.txt
<*IN*>
<*MR.*>
<NOISE>
2020-11-27T21:08:16 (asr.sh:383:main) Skip stage 2: Speed perturbation
2020-11-27T21:08:16 (asr.sh:429:main) [Require Kaldi] Stage 3: fbank_pitch extract: data/ -> dump/fbank_pitch
utils/copy_data_dir.sh: copied data from data/train_si84 to dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
2020-11-27T21:09:14 (asr.sh:214:main) ./asr.sh --lang en --use_lm false --token_type char --nbpe 80 --nlsyms_txt data/nlsyms.txt --lm_config conf/train_lm_transformer.yaml --asr_config conf/train_asr_transformer.yaml --inference_config conf/decode.yaml --train_set train_si84 --valid_set test_dev93 --test_sets test_dev93 test_eval92 --bpe_train_text data/train_si284/text --lm_train_text data/train_si284/text data/local/other_text/text --ngpu 1 --feats_type fbank_pitch
2020-11-27T21:09:19 (asr.sh:364:main) Stage 1: Data preparation for data/train_si84, data/test_dev93, etc.
2020-11-27T21:09:19 (data.sh:37:main) local/wsj_data_prep.sh /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_1/??-{?,??}.? /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/??-{?,??}.?
Data preparation succeeded
2020-11-27T21:09:19 (data.sh:39:main) local/wsj_format_data.sh
local/wsj_format_data.sh 
Preparing train and test data
Succeeded in formatting data.
2020-11-27T21:09:21 (data.sh:43:main) Prepare text from lng_modl dir: /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/13-32.1/wsj1/doc/lng_modl/lm_train/np_data/{87,88,89}/*.z -> data/local/other_text/text
2020-11-27T21:09:48 (data.sh:53:main) Create non linguistic symbols: data/nlsyms.txt
<*IN*>
<*MR.*>
<NOISE>
2020-11-27T21:09:48 (asr.sh:383:main) Skip stage 2: Speed perturbation
2020-11-27T21:09:48 (asr.sh:429:main) [Require Kaldi] Stage 3: fbank_pitch extract: data/ -> dump/fbank_pitch
utils/copy_data_dir.sh: copied data from data/train_si84 to dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_fbank_pitch.sh: Succeeded creating filterbank and pitch features for train_si84
fix_data_dir.sh: kept all 7138 utterances.
fix_data_dir.sh: old files are kept in dump/fbank_pitch/org/train_si84/.backup
Data preparation succeeded
2020-11-27T21:10:58 (data.sh:39:main) local/wsj_format_data.sh
local/wsj_format_data.sh 
Preparing train and test data
Succeeded in formatting data.
2020-11-27T21:11:01 (data.sh:43:main) Prepare text from lng_modl dir: /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/13-32.1/wsj1/doc/lng_modl/lm_train/np_data/{87,88,89}/*.z -> data/local/other_text/text
utils/copy_data_dir.sh: copied data from data/test_dev93 to dump/fbank_pitch/org/test_dev93
utils/copy_data_dir.sh: file feats.scp exists in dest dump/fbank_pitch/org/test_dev93 but not in src data/test_dev93.  Moving it to
 ... dump/fbank_pitch/org/test_dev93/.backup/feats.scp
utils/copy_data_dir.sh: file utt2dur exists in dest dump/fbank_pitch/org/test_dev93 but not in src data/test_dev93.  Moving it to
 ... dump/fbank_pitch/org/test_dev93/.backup/utt2dur
utils/copy_data_dir.sh: file utt2num_frames exists in dest dump/fbank_pitch/org/test_dev93 but not in src data/test_dev93.  Moving it to
 ... dump/fbank_pitch/org/test_dev93/.backup/utt2num_frames
utils/copy_data_dir.sh: file frame_shift exists in dest dump/fbank_pitch/org/test_dev93 but not in src data/test_dev93.  Moving it to
 ... dump/fbank_pitch/org/test_dev93/.backup/frame_shift
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/test_dev93
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/test_dev93
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/test_dev93
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_fbank_pitch.sh: Succeeded creating filterbank and pitch features for test_dev93
fix_data_dir.sh: kept all 503 utterances.
fix_data_dir.sh: old files are kept in dump/fbank_pitch/org/test_dev93/.backup
utils/copy_data_dir.sh: copied data from data/test_dev93 to dump/fbank_pitch/org/test_dev93
utils/copy_data_dir.sh: file feats.scp exists in dest dump/fbank_pitch/org/test_dev93 but not in src data/test_dev93.  Moving it to
 ... dump/fbank_pitch/org/test_dev93/.backup/feats.scp
utils/copy_data_dir.sh: file utt2dur exists in dest dump/fbank_pitch/org/test_dev93 but not in src data/test_dev93.  Moving it to
 ... dump/fbank_pitch/org/test_dev93/.backup/utt2dur
utils/copy_data_dir.sh: file utt2num_frames exists in dest dump/fbank_pitch/org/test_dev93 but not in src data/test_dev93.  Moving it to
 ... dump/fbank_pitch/org/test_dev93/.backup/utt2num_frames
utils/copy_data_dir.sh: file frame_shift exists in dest dump/fbank_pitch/org/test_dev93 but not in src data/test_dev93.  Moving it to
 ... dump/fbank_pitch/org/test_dev93/.backup/frame_shift
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/test_dev93
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/test_dev93
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/test_dev93
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_fbank_pitch.sh: Succeeded creating filterbank and pitch features for test_dev93
fix_data_dir.sh: kept all 503 utterances.
fix_data_dir.sh: old files are kept in dump/fbank_pitch/org/test_dev93/.backup
utils/copy_data_dir.sh: copied data from data/test_eval92 to dump/fbank_pitch/test_eval92
utils/copy_data_dir.sh: file feats.scp exists in dest dump/fbank_pitch/test_eval92 but not in src data/test_eval92.  Moving it to
 ... dump/fbank_pitch/test_eval92/.backup/feats.scp
utils/copy_data_dir.sh: file utt2dur exists in dest dump/fbank_pitch/test_eval92 but not in src data/test_eval92.  Moving it to
 ... dump/fbank_pitch/test_eval92/.backup/utt2dur
utils/copy_data_dir.sh: file utt2num_frames exists in dest dump/fbank_pitch/test_eval92 but not in src data/test_eval92.  Moving it to
 ... dump/fbank_pitch/test_eval92/.backup/utt2num_frames
utils/copy_data_dir.sh: file frame_shift exists in dest dump/fbank_pitch/test_eval92 but not in src data/test_eval92.  Moving it to
 ... dump/fbank_pitch/test_eval92/.backup/frame_shift
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/test_eval92
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/test_eval92
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/test_eval92
2020-11-27T21:11:38 (data.sh:53:main) Create non linguistic symbols: data/nlsyms.txt
<*IN*>
<*MR.*>
<NOISE>
2020-11-27T21:11:39 (asr.sh:383:main) Skip stage 2: Speed perturbation
2020-11-27T21:11:39 (asr.sh:429:main) [Require Kaldi] Stage 3: fbank_pitch extract: data/ -> dump/fbank_pitch
utils/copy_data_dir.sh: copied data from data/train_si84 to dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh: Succeeded creating filterbank and pitch features for test_eval92
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
fix_data_dir.sh: kept all 333 utterances.
fix_data_dir.sh: old files are kept in dump/fbank_pitch/test_eval92/.backup
2020-11-27T21:12:19 (asr.sh:490:main) Stage 4: Remove long/short data: dump/fbank_pitch/org -> dump/fbank_pitch
utils/copy_data_dir.sh: copied data from dump/fbank_pitch/org/train_si84 to dump/fbank_pitch/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/train_si84
fix_data_dir.sh: kept 7137 utterances out of 7138
steps/make_fbank_pitch.sh: Succeeded creating filterbank and pitch features for train_si84
fix_data_dir.sh: old files are kept in dump/fbank_pitch/train_si84/.backup
utils/copy_data_dir.sh: copied data from dump/fbank_pitch/org/test_dev93 to dump/fbank_pitch/test_dev93
fix_data_dir.sh: kept all 7138 utterances.
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/test_dev93
fix_data_dir.sh: old files are kept in dump/fbank_pitch/org/train_si84/.backup
fix_data_dir.sh: kept all 503 utterances.
fix_data_dir.sh: old files are kept in dump/fbank_pitch/test_dev93/.backup
utils/copy_data_dir.sh: copied data from data/test_dev93 to dump/fbank_pitch/org/test_dev93
utils/copy_data_dir.sh: file feats.scp exists in dest dump/fbank_pitch/org/test_dev93 but not in src data/test_dev93.  Moving it to
 ... dump/fbank_pitch/org/test_dev93/.backup/feats.scp
utils/copy_data_dir.sh: file utt2dur exists in dest dump/fbank_pitch/org/test_dev93 but not in src data/test_dev93.  Moving it to
 ... dump/fbank_pitch/org/test_dev93/.backup/utt2dur
utils/copy_data_dir.sh: file utt2num_frames exists in dest dump/fbank_pitch/org/test_dev93 but not in src data/test_dev93.  Moving it to
 ... dump/fbank_pitch/org/test_dev93/.backup/utt2num_frames
utils/copy_data_dir.sh: file frame_shift exists in dest dump/fbank_pitch/org/test_dev93 but not in src data/test_dev93.  Moving it to
 ... dump/fbank_pitch/org/test_dev93/.backup/frame_shift
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/test_dev93
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/test_dev93
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/test_dev93
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_fbank_pitch.sh: Succeeded creating filterbank and pitch features for test_dev93
fix_data_dir.sh: kept all 503 utterances.
fix_data_dir.sh: old files are kept in dump/fbank_pitch/org/test_dev93/.backup
utils/copy_data_dir.sh: copied data from data/test_dev93 to dump/fbank_pitch/org/test_dev93
utils/copy_data_dir.sh: file feats.scp exists in dest dump/fbank_pitch/org/test_dev93 but not in src data/test_dev93.  Moving it to
 ... dump/fbank_pitch/org/test_dev93/.backup/feats.scp
utils/copy_data_dir.sh: file utt2dur exists in dest dump/fbank_pitch/org/test_dev93 but not in src data/test_dev93.  Moving it to
 ... dump/fbank_pitch/org/test_dev93/.backup/utt2dur
utils/copy_data_dir.sh: file utt2num_frames exists in dest dump/fbank_pitch/org/test_dev93 but not in src data/test_dev93.  Moving it to
 ... dump/fbank_pitch/org/test_dev93/.backup/utt2num_frames
utils/copy_data_dir.sh: file frame_shift exists in dest dump/fbank_pitch/org/test_dev93 but not in src data/test_dev93.  Moving it to
 ... dump/fbank_pitch/org/test_dev93/.backup/frame_shift
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/test_dev93
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/test_dev93
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/test_dev93
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_fbank_pitch.sh: Succeeded creating filterbank and pitch features for test_dev93
fix_data_dir.sh: kept all 503 utterances.
fix_data_dir.sh: old files are kept in dump/fbank_pitch/org/test_dev93/.backup
utils/copy_data_dir.sh: copied data from data/test_eval92 to dump/fbank_pitch/test_eval92
utils/copy_data_dir.sh: file feats.scp exists in dest dump/fbank_pitch/test_eval92 but not in src data/test_eval92.  Moving it to
 ... dump/fbank_pitch/test_eval92/.backup/feats.scp
utils/copy_data_dir.sh: file utt2dur exists in dest dump/fbank_pitch/test_eval92 but not in src data/test_eval92.  Moving it to
 ... dump/fbank_pitch/test_eval92/.backup/utt2dur
utils/copy_data_dir.sh: file utt2num_frames exists in dest dump/fbank_pitch/test_eval92 but not in src data/test_eval92.  Moving it to
 ... dump/fbank_pitch/test_eval92/.backup/utt2num_frames
utils/copy_data_dir.sh: file frame_shift exists in dest dump/fbank_pitch/test_eval92 but not in src data/test_eval92.  Moving it to
 ... dump/fbank_pitch/test_eval92/.backup/frame_shift
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/test_eval92
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/test_eval92
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/test_eval92
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
2020-11-27T21:13:36 (asr.sh:585:main) Stage 5: Generate character level token_list from data/train_si284/text data/local/other_text/text
steps/make_fbank_pitch.sh: Succeeded creating filterbank and pitch features for test_eval92
fix_data_dir.sh: kept all 333 utterances.
fix_data_dir.sh: old files are kept in dump/fbank_pitch/test_eval92/.backup
2020-11-27T21:13:43 (asr.sh:490:main) Stage 4: Remove long/short data: dump/fbank_pitch/org -> dump/fbank_pitch
utils/copy_data_dir.sh: copied data from dump/fbank_pitch/org/train_si84 to dump/fbank_pitch/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/train_si84
fix_data_dir.sh: kept 7137 utterances out of 7138
fix_data_dir.sh: old files are kept in dump/fbank_pitch/train_si84/.backup
utils/copy_data_dir.sh: copied data from dump/fbank_pitch/org/test_dev93 to dump/fbank_pitch/test_dev93
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/test_dev93
fix_data_dir.sh: kept all 503 utterances.
fix_data_dir.sh: old files are kept in dump/fbank_pitch/test_dev93/.backup
2020-11-27T21:14:14 (asr.sh:585:main) Stage 5: Generate character level token_list from data/train_si284/text data/local/other_text/text
2020-11-27T21:16:30 (asr.sh:806:main) Stage 6-8: Skip lm-related stages: use_lm=false
2020-11-27T21:16:30 (asr.sh:813:main) Stage 9: ASR collect stats: train_set=dump/fbank_pitch/train_si84, valid_set=dump/fbank_pitch/test_dev93
2020-11-27T21:16:30 (asr.sh:863:main) Generate 'exp/asr_stats_fbank_pitch_char/run.sh'. You can resume the process from stage 9 using this script
2020-11-27T21:16:30 (asr.sh:867:main) ASR collect-stats started... log: 'exp/asr_stats_fbank_pitch_char/logdir/stats.*.log'
2020-11-27T21:17:03 (asr.sh:806:main) Stage 6-8: Skip lm-related stages: use_lm=false
2020-11-27T21:17:03 (asr.sh:813:main) Stage 9: ASR collect stats: train_set=dump/fbank_pitch/train_si84, valid_set=dump/fbank_pitch/test_dev93
2020-11-27T21:17:03 (asr.sh:863:main) Generate 'exp/asr_stats_fbank_pitch_char/run.sh'. You can resume the process from stage 9 using this script
2020-11-27T21:17:03 (asr.sh:867:main) ASR collect-stats started... log: 'exp/asr_stats_fbank_pitch_char/logdir/stats.*.log'
2020-11-27T21:17:15 (asr.sh:914:main) Stage 10: ASR Training: train_set=dump/fbank_pitch/train_si84, valid_set=dump/fbank_pitch/test_dev93
2020-11-27T21:17:15 (asr.sh:981:main) Generate 'exp/asr_train_asr_transformer_fbank_pitch_char/run.sh'. You can resume the process from stage 10 using this script
2020-11-27T21:17:15 (asr.sh:985:main) ASR training started... log: 'exp/asr_train_asr_transformer_fbank_pitch_char/train.log'
2020-11-27T21:17:21 (asr.sh:914:main) Stage 10: ASR Training: train_set=dump/fbank_pitch/train_si84, valid_set=dump/fbank_pitch/test_dev93
2020-11-27T21:17:21 (asr.sh:981:main) Generate 'exp/asr_train_asr_transformer_fbank_pitch_char/run.sh'. You can resume the process from stage 10 using this script
2020-11-27T21:17:21 (asr.sh:985:main) ASR training started... log: 'exp/asr_train_asr_transformer_fbank_pitch_char/train.log'

Failed a run
RUNNING:


run.pl: 32 / 32 failed, log is in dump/fbank_pitch/org/train_si84/log/make_fbank_pitch_train_si84.*.log

Failed a run
RUNNING:-dup


run.pl: 32 / 32 failed, log is in dump/fbank_pitch/org/train_si84/log/make_fbank_pitch_train_si84.*.log

Failed a run
RUNNING:


run.pl: 32 / 32 failed, log is in dump/fbank_pitch/org/train_si84/log/make_fbank_pitch_train_si84.*.log

Failed a run
RUNNING:-dup


run.pl: 32 / 32 failed, log is in dump/fbank_pitch/org/train_si84/log/make_fbank_pitch_train_si84.*.log

Failed a run
RUNNING:


run.pl: 32 / 32 failed, log is in dump/fbank_pitch/org/train_si84/log/make_fbank_pitch_train_si84.*.log

Failed a run
RUNNING:-dup


run.pl: 32 / 32 failed, log is in dump/fbank_pitch/org/train_si84/log/make_fbank_pitch_train_si84.*.log

Failed a run
RUNNING:


scripts/feats/feat_to_shape.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/train_si84/feats.scp dump/fbank_pitch/org/train_si84/feats_shape
scripts/feats/feat_to_shape.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/test_dev93/feats.scp dump/fbank_pitch/org/test_dev93/feats_shape
scripts/feats/feat_to_shape.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/test_dev93/feats.scp dump/fbank_pitch/org/test_dev93/feats_shape
scripts/feats/feat_to_shape.sh --nj 32 --cmd run.pl dump/fbank_pitch/test_eval92/feats.scp dump/fbank_pitch/test_eval92/feats_shape
/afs/cs.pitt.edu/usr0/ras306/miniconda3/envs/psinet/bin/python3 /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/bin/tokenize_text.py --token_type char --input dump/fbank_pitch/lm_train.txt --output data/token_list/char/tokens.txt --non_linguistic_symbols data/nlsyms.txt --field 2- --cleaner none --g2p none --write_vocabulary true --add_symbol '<blank>:0' --add_symbol '<unk>:1' --add_symbol '<sos/eos>:-1'
2020-11-27 21:17:02,944 (tokenize_text:171) INFO: OOV rate = 0.0 %
/afs/cs.pitt.edu/usr0/ras306/miniconda3/envs/psinet/bin/python3 /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/bin/aggregate_stats_dirs.py --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.1 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.2 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.3 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.4 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.5 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.6 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.7 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.8 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.9 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.10 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.11 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.12 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.13 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.14 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.15 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.16 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.17 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.18 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.19 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.20 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.21 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.22 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.23 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.24 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.25 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.26 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.27 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.28 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.29 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.30 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.31 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.32 --output_dir exp/asr_stats_fbank_pitch_char
2020-11-27 21:17:21,412 (launch:95) INFO: /afs/cs.pitt.edu/usr0/ras306/miniconda3/envs/psinet/bin/python3 /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/bin/launch.py --cmd 'run.pl --name exp/asr_train_asr_transformer_fbank_pitch_char/train.log' --log exp/asr_train_asr_transformer_fbank_pitch_char/train.log --ngpu 1 --num_nodes 1 --init_file_prefix exp/asr_train_asr_transformer_fbank_pitch_char/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel none --token_type char --token_list data/token_list/char/tokens.txt --non_linguistic_symbols data/nlsyms.txt --cleaner none --g2p none --valid_data_path_and_name_and_type dump/fbank_pitch/test_dev93/feats.scp,speech,kaldi_ark --valid_data_path_and_name_and_type dump/fbank_pitch/test_dev93/text,text,text --valid_shape_file exp/asr_stats_fbank_pitch_char/valid/speech_shape --valid_shape_file exp/asr_stats_fbank_pitch_char/valid/text_shape.char --resume true --fold_length 800 --fold_length 150 --output_dir exp/asr_train_asr_transformer_fbank_pitch_char --config conf/train_asr_transformer.yaml --input_size=73 --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_fbank_pitch_char/train/feats_stats.npz --train_data_path_and_name_and_type dump/fbank_pitch/train_si84/feats.scp,speech,kaldi_ark --train_data_path_and_name_and_type dump/fbank_pitch/train_si84/text,text,text --train_shape_file exp/asr_stats_fbank_pitch_char/train/speech_shape --train_shape_file exp/asr_stats_fbank_pitch_char/train/text_shape.char
2020-11-27 21:17:21,532 (launch:349) INFO: log file: exp/asr_train_asr_transformer_fbank_pitch_char/train.log
run.pl: job failed, log is in exp/asr_train_asr_transformer_fbank_pitch_char/train.log
Command '['run.pl', '--name', 'exp/asr_train_asr_transformer_fbank_pitch_char/train.log', '--gpu', '1', 'exp/asr_train_asr_transformer_fbank_pitch_char/train.log', 'python3', '-m', 'espnet2.bin.asr_train', '--use_preprocessor', 'true', '--bpemodel', 'none', '--token_type', 'char', '--token_list', 'data/token_list/char/tokens.txt', '--non_linguistic_symbols', 'data/nlsyms.txt', '--cleaner', 'none', '--g2p', 'none', '--valid_data_path_and_name_and_type', 'dump/fbank_pitch/test_dev93/feats.scp,speech,kaldi_ark', '--valid_data_path_and_name_and_type', 'dump/fbank_pitch/test_dev93/text,text,text', '--valid_shape_file', 'exp/asr_stats_fbank_pitch_char/valid/speech_shape', '--valid_shape_file', 'exp/asr_stats_fbank_pitch_char/valid/text_shape.char', '--resume', 'true', '--fold_length', '800', '--fold_length', '150', '--output_dir', 'exp/asr_train_asr_transformer_fbank_pitch_char', '--config', 'conf/train_asr_transformer.yaml', '--input_size=73', '--normalize=global_mvn', '--normalize_conf', 'stats_file=exp/asr_stats_fbank_pitch_char/train/feats_stats.npz', '--train_data_path_and_name_and_type', 'dump/fbank_pitch/train_si84/feats.scp,speech,kaldi_ark', '--train_data_path_and_name_and_type', 'dump/fbank_pitch/train_si84/text,text,text', '--train_shape_file', 'exp/asr_stats_fbank_pitch_char/train/speech_shape', '--train_shape_file', 'exp/asr_stats_fbank_pitch_char/train/text_shape.char', '--ngpu', '1', '--multiprocessing_distributed', 'True']' returned non-zero exit status 1.
Traceback (most recent call last):
  File "/afs/cs.pitt.edu/usr0/ras306/miniconda3/envs/psinet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/afs/cs.pitt.edu/usr0/ras306/miniconda3/envs/psinet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/bin/launch.py", line 385, in <module>
    main()
  File "/afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/bin/launch.py", line 378, in main
    f"###################\n" + "".join(lines[-1000:])
RuntimeError: 
################### The last 1000 lines of exp/asr_train_asr_transformer_fbank_pitch_char/train.log ###################
# python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel none --token_type char --token_list data/token_list/char/tokens.txt --non_linguistic_symbols data/nlsyms.txt --cleaner none --g2p none --valid_data_path_and_name_and_type dump/fbank_pitch/test_dev93/feats.scp,speech,kaldi_ark --valid_data_path_and_name_and_type dump/fbank_pitch/test_dev93/text,text,text --valid_shape_file exp/asr_stats_fbank_pitch_char/valid/speech_shape --valid_shape_file exp/asr_stats_fbank_pitch_char/valid/text_shape.char --resume true --fold_length 800 --fold_length 150 --output_dir exp/asr_train_asr_transformer_fbank_pitch_char --config conf/train_asr_transformer.yaml --input_size=73 --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_fbank_pitch_char/train/feats_stats.npz --train_data_path_and_name_and_type dump/fbank_pitch/train_si84/feats.scp,speech,kaldi_ark --train_data_path_and_name_and_type dump/fbank_pitch/train_si84/text,text,text --train_shape_file exp/asr_stats_fbank_pitch_char/train/speech_shape --train_shape_file exp/asr_stats_fbank_pitch_char/train/text_shape.char --ngpu 1 --multiprocessing_distributed True 
# Started at Fri Nov 27 21:17:21 EST 2020
#
/afs/cs.pitt.edu/usr0/ras306/miniconda3/envs/psinet/bin/python3 /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/bin/asr_train.py --use_preprocessor true --bpemodel none --token_type char --token_list data/token_list/char/tokens.txt --non_linguistic_symbols data/nlsyms.txt --cleaner none --g2p none --valid_data_path_and_name_and_type dump/fbank_pitch/test_dev93/feats.scp,speech,kaldi_ark --valid_data_path_and_name_and_type dump/fbank_pitch/test_dev93/text,text,text --valid_shape_file exp/asr_stats_fbank_pitch_char/valid/speech_shape --valid_shape_file exp/asr_stats_fbank_pitch_char/valid/text_shape.char --resume true --fold_length 800 --fold_length 150 --output_dir exp/asr_train_asr_transformer_fbank_pitch_char --config conf/train_asr_transformer.yaml --input_size=73 --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_fbank_pitch_char/train/feats_stats.npz --train_data_path_and_name_and_type dump/fbank_pitch/train_si84/feats.scp,speech,kaldi_ark --train_data_path_and_name_and_type dump/fbank_pitch/train_si84/text,text,text --train_shape_file exp/asr_stats_fbank_pitch_char/train/speech_shape --train_shape_file exp/asr_stats_fbank_pitch_char/train/text_shape.char --ngpu 1 --multiprocessing_distributed True
[magnolia] 2020-11-27 21:17:23,247 (asr:283) INFO: Vocabulary size: 65
[magnolia] 2020-11-27 21:17:55,955 (abs_task:1068) INFO: pytorch.version=1.4.0, cuda.available=True, cudnn.version=7603, cudnn.benchmark=False, cudnn.deterministic=True
[magnolia] 2020-11-27 21:17:55,959 (abs_task:1069) INFO: Model structure:
ESPnetASRModel(
  (normalize): GlobalMVN(stats_file=exp/asr_stats_fbank_pitch_char/train/feats_stats.npz, norm_means=True, norm_vars=True)
  (encoder): TransformerEncoder(
    (embed): Conv2dSubsampling(
      (conv): Sequential(
        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=4352, out_features=256, bias=True)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (encoders): MultiSequential(
      (0): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (2): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (3): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (4): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (5): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (6): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (7): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (8): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (9): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (10): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (11): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (embed): Sequential(
      (0): Embedding(65, 256)
      (1): PositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
    (output_layer): Linear(in_features=256, out_features=65, bias=True)
    (decoders): MultiSequential(
      (0): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (2): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (3): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (4): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (5): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=256, out_features=65, bias=True)
    (ctc_loss): CTCLoss()
  )
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
)

Model summary:
    Class Name: ESPnetASRModel
    Number of parameters: 27.01 M
    Size: 108.05 MB
    Type: torch.float32
[magnolia] 2020-11-27 21:17:55,959 (abs_task:1072) INFO: Optimizer:
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.005
    lr: 1.6666666666666665e-07
    weight_decay: 0
)
[magnolia] 2020-11-27 21:17:55,959 (abs_task:1073) INFO: Scheduler: WarmupLR(warmup_steps=30000)
[magnolia] 2020-11-27 21:17:55,971 (abs_task:1083) INFO: Saving the configuration in exp/asr_train_asr_transformer_fbank_pitch_char/config.yaml
Traceback (most recent call last):
  File "/afs/cs.pitt.edu/usr0/ras306/miniconda3/envs/psinet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/afs/cs.pitt.edu/usr0/ras306/miniconda3/envs/psinet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/bin/asr_train.py", line 23, in <module>
    main()
  File "/afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/bin/asr_train.py", line 19, in main
    ASRTask.main(cmd=cmd)
  File "/afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/tasks/abs_task.py", line 941, in main
    cls.main_worker(args)
  File "/afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/tasks/abs_task.py", line 1122, in main_worker
    ngpu=args.ngpu,
  File "/afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/tasks/abs_task.py", line 899, in resume
    model.load_state_dict(states["model"])
  File "/afs/cs.pitt.edu/usr0/ras306/miniconda3/envs/psinet/lib/python3.7/site-packages/torch/nn/modules/module.py", line 830, in load_state_dict
    self.__class__.__name__, "\n\t".join(error_msgs)))
RuntimeError: Error(s) in loading state_dict for ESPnetASRModel:
	size mismatch for normalize.mean: copying a param with shape torch.Size([26]) from checkpoint, the shape in current model is torch.Size([73]).
	size mismatch for normalize.std: copying a param with shape torch.Size([26]) from checkpoint, the shape in current model is torch.Size([73]).
	size mismatch for encoder.embed.out.0.weight: copying a param with shape torch.Size([256, 1280]) from checkpoint, the shape in current model is torch.Size([256, 4352]).
# Accounting: time=75 threads=1
# Ended (code 1) at Fri Nov 27 21:18:36 EST 2020, elapsed time 75 seconds

2020-11-27T21:18:36 (asr.sh:214:main) ./asr.sh --lang en --use_lm false --token_type char --nbpe 80 --nlsyms_txt data/nlsyms.txt --lm_config conf/train_lm_transformer.yaml --asr_config conf/train_asr_transformer.yaml --inference_config conf/decode.yaml --train_set train_si84 --valid_set test_dev93 --test_sets test_dev93 test_eval92 --bpe_train_text data/train_si284/text --lm_train_text data/train_si284/text data/local/other_text/text --ngpu 1 --feats_type fbank_pitch

Failed a run
RUNNING:


scripts/feats/feat_to_shape.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/train_si84/feats.scp dump/fbank_pitch/org/train_si84/feats_shape
scripts/feats/feat_to_shape.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/test_dev93/feats.scp dump/fbank_pitch/org/test_dev93/feats_shape
scripts/feats/feat_to_shape.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/test_dev93/feats.scp dump/fbank_pitch/org/test_dev93/feats_shape
scripts/feats/feat_to_shape.sh --nj 32 --cmd run.pl dump/fbank_pitch/test_eval92/feats.scp dump/fbank_pitch/test_eval92/feats_shape
/afs/cs.pitt.edu/usr0/ras306/miniconda3/envs/psinet/bin/python3 /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/bin/tokenize_text.py --token_type char --input dump/fbank_pitch/lm_train.txt --output data/token_list/char/tokens.txt --non_linguistic_symbols data/nlsyms.txt --field 2- --cleaner none --g2p none --write_vocabulary true --add_symbol '<blank>:0' --add_symbol '<unk>:1' --add_symbol '<sos/eos>:-1'
2020-11-27 21:16:30,310 (tokenize_text:171) INFO: OOV rate = 0.0 %
/afs/cs.pitt.edu/usr0/ras306/miniconda3/envs/psinet/bin/python3 /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/bin/aggregate_stats_dirs.py --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.1 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.2 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.3 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.4 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.5 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.6 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.7 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.8 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.9 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.10 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.11 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.12 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.13 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.14 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.15 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.16 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.17 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.18 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.19 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.20 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.21 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.22 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.23 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.24 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.25 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.26 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.27 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.28 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.29 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.30 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.31 --input_dir exp/asr_stats_fbank_pitch_char/logdir/stats.32 --output_dir exp/asr_stats_fbank_pitch_char
2020-11-27 21:17:15,670 (launch:95) INFO: /afs/cs.pitt.edu/usr0/ras306/miniconda3/envs/psinet/bin/python3 /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/bin/launch.py --cmd 'run.pl --name exp/asr_train_asr_transformer_fbank_pitch_char/train.log' --log exp/asr_train_asr_transformer_fbank_pitch_char/train.log --ngpu 1 --num_nodes 1 --init_file_prefix exp/asr_train_asr_transformer_fbank_pitch_char/.dist_init_ --multiprocessing_distributed true -- python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel none --token_type char --token_list data/token_list/char/tokens.txt --non_linguistic_symbols data/nlsyms.txt --cleaner none --g2p none --valid_data_path_and_name_and_type dump/fbank_pitch/test_dev93/feats.scp,speech,kaldi_ark --valid_data_path_and_name_and_type dump/fbank_pitch/test_dev93/text,text,text --valid_shape_file exp/asr_stats_fbank_pitch_char/valid/speech_shape --valid_shape_file exp/asr_stats_fbank_pitch_char/valid/text_shape.char --resume true --fold_length 800 --fold_length 150 --output_dir exp/asr_train_asr_transformer_fbank_pitch_char --config conf/train_asr_transformer.yaml --input_size=48 --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_fbank_pitch_char/train/feats_stats.npz --train_data_path_and_name_and_type dump/fbank_pitch/train_si84/feats.scp,speech,kaldi_ark --train_data_path_and_name_and_type dump/fbank_pitch/train_si84/text,text,text --train_shape_file exp/asr_stats_fbank_pitch_char/train/speech_shape --train_shape_file exp/asr_stats_fbank_pitch_char/train/text_shape.char
2020-11-27 21:17:15,719 (launch:349) INFO: log file: exp/asr_train_asr_transformer_fbank_pitch_char/train.log
run.pl: job failed, log is in exp/asr_train_asr_transformer_fbank_pitch_char/train.log
Command '['run.pl', '--name', 'exp/asr_train_asr_transformer_fbank_pitch_char/train.log', '--gpu', '1', 'exp/asr_train_asr_transformer_fbank_pitch_char/train.log', 'python3', '-m', 'espnet2.bin.asr_train', '--use_preprocessor', 'true', '--bpemodel', 'none', '--token_type', 'char', '--token_list', 'data/token_list/char/tokens.txt', '--non_linguistic_symbols', 'data/nlsyms.txt', '--cleaner', 'none', '--g2p', 'none', '--valid_data_path_and_name_and_type', 'dump/fbank_pitch/test_dev93/feats.scp,speech,kaldi_ark', '--valid_data_path_and_name_and_type', 'dump/fbank_pitch/test_dev93/text,text,text', '--valid_shape_file', 'exp/asr_stats_fbank_pitch_char/valid/speech_shape', '--valid_shape_file', 'exp/asr_stats_fbank_pitch_char/valid/text_shape.char', '--resume', 'true', '--fold_length', '800', '--fold_length', '150', '--output_dir', 'exp/asr_train_asr_transformer_fbank_pitch_char', '--config', 'conf/train_asr_transformer.yaml', '--input_size=48', '--normalize=global_mvn', '--normalize_conf', 'stats_file=exp/asr_stats_fbank_pitch_char/train/feats_stats.npz', '--train_data_path_and_name_and_type', 'dump/fbank_pitch/train_si84/feats.scp,speech,kaldi_ark', '--train_data_path_and_name_and_type', 'dump/fbank_pitch/train_si84/text,text,text', '--train_shape_file', 'exp/asr_stats_fbank_pitch_char/train/speech_shape', '--train_shape_file', 'exp/asr_stats_fbank_pitch_char/train/text_shape.char', '--ngpu', '1', '--multiprocessing_distributed', 'True']' returned non-zero exit status 1.
Traceback (most recent call last):
  File "/afs/cs.pitt.edu/usr0/ras306/miniconda3/envs/psinet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/afs/cs.pitt.edu/usr0/ras306/miniconda3/envs/psinet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/bin/launch.py", line 385, in <module>
    main()
  File "/afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/bin/launch.py", line 378, in main
    f"###################\n" + "".join(lines[-1000:])
RuntimeError: 
################### The last 1000 lines of exp/asr_train_asr_transformer_fbank_pitch_char/train.log ###################
# python3 -m espnet2.bin.asr_train --use_preprocessor true --bpemodel none --token_type char --token_list data/token_list/char/tokens.txt --non_linguistic_symbols data/nlsyms.txt --cleaner none --g2p none --valid_data_path_and_name_and_type dump/fbank_pitch/test_dev93/feats.scp,speech,kaldi_ark --valid_data_path_and_name_and_type dump/fbank_pitch/test_dev93/text,text,text --valid_shape_file exp/asr_stats_fbank_pitch_char/valid/speech_shape --valid_shape_file exp/asr_stats_fbank_pitch_char/valid/text_shape.char --resume true --fold_length 800 --fold_length 150 --output_dir exp/asr_train_asr_transformer_fbank_pitch_char --config conf/train_asr_transformer.yaml --input_size=48 --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_fbank_pitch_char/train/feats_stats.npz --train_data_path_and_name_and_type dump/fbank_pitch/train_si84/feats.scp,speech,kaldi_ark --train_data_path_and_name_and_type dump/fbank_pitch/train_si84/text,text,text --train_shape_file exp/asr_stats_fbank_pitch_char/train/speech_shape --train_shape_file exp/asr_stats_fbank_pitch_char/train/text_shape.char --ngpu 1 --multiprocessing_distributed True 
# Started at Fri Nov 27 21:17:16 EST 2020
#
/afs/cs.pitt.edu/usr0/ras306/miniconda3/envs/psinet/bin/python3 /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/bin/asr_train.py --use_preprocessor true --bpemodel none --token_type char --token_list data/token_list/char/tokens.txt --non_linguistic_symbols data/nlsyms.txt --cleaner none --g2p none --valid_data_path_and_name_and_type dump/fbank_pitch/test_dev93/feats.scp,speech,kaldi_ark --valid_data_path_and_name_and_type dump/fbank_pitch/test_dev93/text,text,text --valid_shape_file exp/asr_stats_fbank_pitch_char/valid/speech_shape --valid_shape_file exp/asr_stats_fbank_pitch_char/valid/text_shape.char --resume true --fold_length 800 --fold_length 150 --output_dir exp/asr_train_asr_transformer_fbank_pitch_char --config conf/train_asr_transformer.yaml --input_size=48 --normalize=global_mvn --normalize_conf stats_file=exp/asr_stats_fbank_pitch_char/train/feats_stats.npz --train_data_path_and_name_and_type dump/fbank_pitch/train_si84/feats.scp,speech,kaldi_ark --train_data_path_and_name_and_type dump/fbank_pitch/train_si84/text,text,text --train_shape_file exp/asr_stats_fbank_pitch_char/train/speech_shape --train_shape_file exp/asr_stats_fbank_pitch_char/train/text_shape.char --ngpu 1 --multiprocessing_distributed True
[magnolia] 2020-11-27 21:17:17,746 (asr:283) INFO: Vocabulary size: 65
[magnolia] 2020-11-27 21:17:55,905 (abs_task:1068) INFO: pytorch.version=1.4.0, cuda.available=True, cudnn.version=7603, cudnn.benchmark=False, cudnn.deterministic=True
[magnolia] 2020-11-27 21:17:55,911 (abs_task:1069) INFO: Model structure:
ESPnetASRModel(
  (normalize): GlobalMVN(stats_file=exp/asr_stats_fbank_pitch_char/train/feats_stats.npz, norm_means=True, norm_vars=True)
  (encoder): TransformerEncoder(
    (embed): Conv2dSubsampling(
      (conv): Sequential(
        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=2816, out_features=256, bias=True)
        (1): PositionalEncoding(
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (encoders): MultiSequential(
      (0): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (2): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (3): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (4): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (5): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (6): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (7): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (8): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (9): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (10): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (11): EncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (embed): Sequential(
      (0): Embedding(65, 256)
      (1): PositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
    (output_layer): Linear(in_features=256, out_features=65, bias=True)
    (decoders): MultiSequential(
      (0): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (1): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (2): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (3): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (4): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (5): DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (activation): ReLU()
        )
        (norm1): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=256, out_features=65, bias=True)
    (ctc_loss): CTCLoss()
  )
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
)

Model summary:
    Class Name: ESPnetASRModel
    Number of parameters: 26.62 M
    Size: 106.47 MB
    Type: torch.float32
[magnolia] 2020-11-27 21:17:55,911 (abs_task:1072) INFO: Optimizer:
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.005
    lr: 1.6666666666666665e-07
    weight_decay: 0
)
[magnolia] 2020-11-27 21:17:55,911 (abs_task:1073) INFO: Scheduler: WarmupLR(warmup_steps=30000)
[magnolia] 2020-11-27 21:17:55,913 (abs_task:1083) INFO: Saving the configuration in exp/asr_train_asr_transformer_fbank_pitch_char/config.yaml
Traceback (most recent call last):
  File "/afs/cs.pitt.edu/usr0/ras306/miniconda3/envs/psinet/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/afs/cs.pitt.edu/usr0/ras306/miniconda3/envs/psinet/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/bin/asr_train.py", line 23, in <module>
    main()
  File "/afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/bin/asr_train.py", line 19, in main
    ASRTask.main(cmd=cmd)
  File "/afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/tasks/abs_task.py", line 941, in main
    cls.main_worker(args)
  File "/afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/tasks/abs_task.py", line 1122, in main_worker
    ngpu=args.ngpu,
  File "/afs/cs.pitt.edu/usr0/ras306/Classwork/Project/PSInet/espnet/espnet2/tasks/abs_task.py", line 899, in resume
    model.load_state_dict(states["model"])
  File "/afs/cs.pitt.edu/usr0/ras306/miniconda3/envs/psinet/lib/python3.7/site-packages/torch/nn/modules/module.py", line 830, in load_state_dict
    self.__class__.__name__, "\n\t".join(error_msgs)))
RuntimeError: Error(s) in loading state_dict for ESPnetASRModel:
	size mismatch for normalize.mean: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([48]).
	size mismatch for normalize.std: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([48]).
	size mismatch for encoder.embed.out.0.weight: copying a param with shape torch.Size([256, 1792]) from checkpoint, the shape in current model is torch.Size([256, 2816]).
# Accounting: time=80 threads=1
# Ended (code 1) at Fri Nov 27 21:18:36 EST 2020, elapsed time 80 seconds

2020-11-27T21:18:36 (asr.sh:214:main) ./asr.sh --lang en --use_lm false --token_type char --nbpe 80 --nlsyms_txt data/nlsyms.txt --lm_config conf/train_lm_transformer.yaml --asr_config conf/train_asr_transformer.yaml --inference_config conf/decode.yaml --train_set train_si84 --valid_set test_dev93 --test_sets test_dev93 test_eval92 --bpe_train_text data/train_si284/text --lm_train_text data/train_si284/text data/local/other_text/text --ngpu 1 --feats_type fbank_pitch
2020-11-27T21:18:37 (asr.sh:364:main) Stage 1: Data preparation for data/train_si84, data/test_dev93, etc.
2020-11-27T21:18:37 (asr.sh:364:main) Stage 1: Data preparation for data/train_si84, data/test_dev93, etc.
2020-11-27T21:18:37 (data.sh:37:main) local/wsj_data_prep.sh /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_1/??-{?,??}.? /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/??-{?,??}.?
2020-11-27T21:18:37 (data.sh:37:main) local/wsj_data_prep.sh /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_1/??-{?,??}.? /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/??-{?,??}.?
Data preparation succeeded
Data preparation succeeded
2020-11-27T21:19:04 (data.sh:39:main) local/wsj_format_data.sh
local/wsj_format_data.sh 
2020-11-27T21:19:04 (data.sh:39:main) local/wsj_format_data.sh
local/wsj_format_data.sh 
Preparing train and test data
Preparing train and test data
Succeeded in formatting data.
Succeeded in formatting data.
2020-11-27T21:19:07 (data.sh:43:main) Prepare text from lng_modl dir: /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/13-32.1/wsj1/doc/lng_modl/lm_train/np_data/{87,88,89}/*.z -> data/local/other_text/text
2020-11-27T21:19:07 (data.sh:43:main) Prepare text from lng_modl dir: /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/13-32.1/wsj1/doc/lng_modl/lm_train/np_data/{87,88,89}/*.z -> data/local/other_text/text
2020-11-27T21:19:51 (data.sh:53:main) Create non linguistic symbols: data/nlsyms.txt
2020-11-27T21:19:51 (data.sh:53:main) Create non linguistic symbols: data/nlsyms.txt
<*IN*>
<*MR.*>
<NOISE>
<*IN*>
<*MR.*>
<NOISE>
2020-11-27T21:19:51 (asr.sh:383:main) Skip stage 2: Speed perturbation
2020-11-27T21:19:51 (asr.sh:383:main) Skip stage 2: Speed perturbation
2020-11-27T21:19:51 (asr.sh:429:main) [Require Kaldi] Stage 3: fbank_pitch extract: data/ -> dump/fbank_pitch
2020-11-27T21:19:51 (asr.sh:429:main) [Require Kaldi] Stage 3: fbank_pitch extract: data/ -> dump/fbank_pitch
utils/copy_data_dir.sh: copied data from data/train_si84 to dump/fbank_pitch/org/train_si84
utils/copy_data_dir.sh: file feats.scp exists in dest dump/fbank_pitch/org/train_si84 but not in src data/train_si84.  Moving it to
 ... dump/fbank_pitch/org/train_si84/.backup/feats.scp
utils/copy_data_dir.sh: file utt2dur exists in dest dump/fbank_pitch/org/train_si84 but not in src data/train_si84.  Moving it to
 ... dump/fbank_pitch/org/train_si84/.backup/utt2dur
utils/copy_data_dir.sh: file utt2num_frames exists in dest dump/fbank_pitch/org/train_si84 but not in src data/train_si84.  Moving it to
 ... dump/fbank_pitch/org/train_si84/.backup/utt2num_frames
utils/copy_data_dir.sh: copied data from data/train_si84 to dump/fbank_pitch/org/train_si84
utils/copy_data_dir.sh: file feats.scp exists in dest dump/fbank_pitch/org/train_si84 but not in src data/train_si84.  Moving it to
 ... dump/fbank_pitch/org/train_si84/.backup/feats.scp
utils/copy_data_dir.sh: file frame_shift exists in dest dump/fbank_pitch/org/train_si84 but not in src data/train_si84.  Moving it to
 ... dump/fbank_pitch/org/train_si84/.backup/frame_shift
utils/copy_data_dir.sh: file utt2dur exists in dest dump/fbank_pitch/org/train_si84 but not in src data/train_si84.  Moving it to
 ... dump/fbank_pitch/org/train_si84/.backup/utt2dur
utils/copy_data_dir.sh: file utt2num_frames exists in dest dump/fbank_pitch/org/train_si84 but not in src data/train_si84.  Moving it to
 ... dump/fbank_pitch/org/train_si84/.backup/utt2num_frames
utils/copy_data_dir.sh: file frame_shift exists in dest dump/fbank_pitch/org/train_si84 but not in src data/train_si84.  Moving it to
 ... dump/fbank_pitch/org/train_si84/.backup/frame_shift
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh --nj 32 --cmd run.pl dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
utils/validate_data_dir.sh: Successfully validated data-directory dump/fbank_pitch/org/train_si84
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
steps/make_fbank_pitch.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.
2020-11-27T21:20:03 (asr.sh:214:main) ./asr.sh --lang en --use_lm false --token_type char --nbpe 80 --nlsyms_txt data/nlsyms.txt --lm_config conf/train_lm_transformer.yaml --asr_config conf/train_asr_transformer.yaml --inference_config conf/decode.yaml --train_set train_si84 --valid_set test_dev93 --test_sets test_dev93 test_eval92 --bpe_train_text data/train_si284/text --lm_train_text data/train_si284/text data/local/other_text/text --ngpu 1 --feats_type fbank_pitch
2020-11-27T21:20:09 (asr.sh:364:main) Stage 1: Data preparation for data/train_si84, data/test_dev93, etc.
2020-11-27T21:20:09 (data.sh:37:main) local/wsj_data_prep.sh /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_1/??-{?,??}.? /afs/cs.pitt.edu/usr0/ras306/Classwork/Project/csr_2/??-{?,??}.?
